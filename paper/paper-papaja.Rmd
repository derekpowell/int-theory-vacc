---
title             : "Modeling and leveraging intuitive theories to improve vaccine attitudes"
shorttitle        : "Intuitive theories of vaccine attitudes"

author: 
  - name          : "Derek Powell"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "4701 W. Thunderbird Road, Glendale, AZ 85306"
    email         : "dmpowell@asu.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Investigation
      - Methodology
      - Data collection
      - Formal Analysis
      - Visualization
      - Writing
  - name          : "Kara Weisman"
    affiliation   : "2"
    role:
      - Conceptualization 6t            
      - Investigation
      - Data collection
      - Formal Analysis
      - Visualization
      - Writing
  - name          : "Ellen M. Markman"
    affiliation   : "3"
    role:
      - Conceptualization
      - Methodology
      - Writing

affiliation:
  - id            : "1"
    institution   : "Arizona State University"
  - id            : "2"
    institution   : "University of California - Riverside"
  - id            : "3"
    institution   : "Stanford University"

note: |
  This manuscript has not yet been peer-reviewed (2/15/2022). 
  
authornote: |
  All data, and analysis code for this project are available at https://osf.io/sdfpj/. Preregistration information for Studies 3a and 3b is available at https://osf.io/csnez/registrations.

abstract: |
  Much of the richness of human thought is supported by people’s intuitive theories---mental frameworks capturing the perceived structure of the world. But intuitive theories can also contain and reinforce dangerous misconceptions. In this paper, we take up the case of misconceptions about vaccine safety that discourage vaccination. These misconceptions constitute a major public health risk that predates the coronavirus pandemic but that has become all the more dire in recent years. We argue that addressing such misconceptions requires awareness of the broader conceptual contexts in which they are embedded. To build this understanding, we examined the structure and revision of people’s intuitive theories of vaccination in five large survey studies (total _N_ = 3196). Based on these data, we present a cognitive model of the intuitive theory surrounding people’s decisions about whether to vaccinate young children against diseases like measles, mumps, and rubella (MMR). Using this model, we were able to make accurate predictions about how people’s beliefs would be revised in light of educational interventions, design an effective new intervention encouraging vaccination, and understand how these beliefs were affected by real-world events (the measles outbreaks of 2019). In addition to presenting a promising way forward for promoting the MMR vaccine, this approach has clear implications for encouraging the uptake of COVID-19 vaccines, especially among parents of young children. At the same time, this work provides the foundation for richer understandings of intuitive theories and belief revision more broadly.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Intuitive theories; Belief revision; Vaccine attitudes; Cognitive modeling"
wordcount         : "9161"

bibliography      : ["../supplement/references.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

documentclass     : "apa7"
csl               : "apa7.csl"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r load-required-data, include=FALSE}
library(tidyverse)
results <- readRDS("../local/paper-results.rds") 
```


One remarkable feature of human psychology is our ability to form rich mental representations of what is true, how things work, and how best to navigate the world around us. Much of this type of thinking can be understood as deriving from people’s *intuitive theories*---explanatory frameworks, analogous to scientific theories, that capture the causal and logical structure of the world within a domain. From early in life, people are driven to seek out such causal explanations and to use their mental representations of these causal systems to explain, predict, and intervene in the world [see @carey2009; @gelman.legare2011; @gerstenberg.etal2021; @gopnik.wellman1994; @keil1994; @murphy.medin1985; @wellman.gelman1992 for influential treatments of this topic].  Intuitive theories inform reasoning in a wide variety of domains, including reasoning about physical systems [e.g., @baillargeon2004; @battaglia.etal2013; @spelke1994a; @ullman.etal2017], biological processes [e.g., @carey1985; @carey2009;  @medin.atran1999] and the contents of other people’s minds [e.g., @baker.etal2017; @gopnik.wellman1994; @wellman2015].

Because intuitive theories are such powerful tools for making sense of the world, when these theories are mistaken there can be serious consequences. In this paper, we focus on an important and timely example: misconceptions about vaccine safety.

Even before the coronavirus pandemic, misconceptions about vaccine safety drove public health crises around the world. Undervaccination resulted in outbreaks of measles affecting over one thousand children across the United States in 2019, and over 80,000 children across Europe in 2018 [@thornton2019]. Misconceptions about childhood vaccination---particularly the fraudulent claim that vaccines cause autism or other dangerous side-effects---have proved remarkably difficult to correct [e.g., @betsch.sachse2013; @horne.etal2015]. Sadly, only a handful of educational interventions have been found to improve vaccine attitudes [e.g., @dube.etal2015; @horne.etal2015; @vannice.etal2011; @wallace.etal2006]. This is especially  sobering in the context of the coronavirus pandemic: widespread reluctance to be vaccinated against COVID-19 threatens our ability to end a pandemic that has already claimed more than five million lives around the world.

The difficulty of convincing people to vaccinate themselves and their children illustrates a general pattern of findings showing that people often do not respond to evidence in ways that educators might wish [e.g. @lewandowsky.etal2012]. Part of the challenge in correcting misconceptions is that they are situated within larger, internally coherent belief systems---intuitive theories---that guide how people interpret and respond to evidence [e.g., @gershman2019; @lewandowsky.etal2012; @jern.etal2014]. 
Consider some of the beliefs people who are skeptical of childhood vaccination expressed when we asked them to explain their views in an open-ended qualitative survey (conducted pre-pandemic; _n_ = 16). Several participants saw vaccines as “unnatural” and expressed concerns about toxic additives in vaccines, such as heavy metals and mercury. One said, “Vaccines are unnatural additions to the body. The human body should naturally fight off the disease and we should not be controlling how nature plays its role on mankind.” Some doubted whether certain diseases were worth worrying over, while others feared that the contents of vaccines “are too strong and too concentrated for a baby’s body to properly handle.” A number of respondents were skeptical of the medical community’s objectivity in testing the safety of vaccines. One respondent wrote that vaccines were “A BIG MONEY MAKING SCAM BY THE BIG PHARMS” (emphasis theirs); another thought that health professionals “are brainwashed by the medical media and the government.” 

To people holding these beliefs, it could well seem unreasonable to vaccinate a 2-month-old baby against five or more diseases at once, as the CDC recommends. Moreover, if skeptics believe that the medical community is unduly influenced by pharmaceutical companies, they might doubt the validity of medical findings that appear to favor these companies’ interests. Altogether, these beliefs might sustain misconceptions about vaccine safety, even in the face of counter-evidence: CDC guidelines, clinical studies, and even the advice of the family’s pediatrician could be interpreted not as evidence that vaccines are safer than the person thought, but instead as further proof of the widespread corruption in the medical community.

The way in which evidence affects any particular belief is unavoidably shaped by other interrelated beliefs. Duhem [-@duhem1954] and Quine [-@quine1951] famously argued that scientific theories necessarily incorporate *auxiliary hypotheses* that influence how observations are interpreted: when an observation is inconsistent with a hypothesis under certain auxiliary assumptions, a scientist cannot know whether to revise the hypothesis or the auxiliary assumptions. Similarly, we argue that intuitive theories incorporate auxiliary beliefs that affect how other beliefs are revised in light of evidence: when an observation is inconsistent with a person’s current belief under certain auxiliary assumptions, the person cannot know whether to revise the belief or the auxiliary assumptions [also see @gershman2019]. 

Here we present a line of theoretical and empirical work that seeks to understand misconceptions and belief revision in the context of people’s intuitive theories. We focus on reducing hesitancy toward childhood vaccination by identifying intuitive theories surrounding these vaccination decisions. Through this case study we hope to shed light on why such misconceptions persist and how interventions might address misconceptions more effectively across domains.

We argue that correcting misconceptions requires presenting evidence in a way that is sensitive to and persuasive within the broader conceptual context in which those misconceptions reside [see @gershman2019; @weisman.markman2017]. Understanding the revision of any one specific belief (e.g., a misconception like *vaccines are dangerous*) demands a holistic understanding of the wider set of interrelated beliefs that make up people's intuitive theories.

## Modeling intuitive theories

Quine argued that all of one’s beliefs are intertwined in a “web of belief” [@quine1951; @quine.ullian1978]---an apt metaphor for intuitive theories. Intuitive theories consist of relations between beliefs that specify how states of affairs causally, logically, or otherwise interconnect with one another. Given this definition, we argue that any set of beliefs related by an intuitive theory can be expected to exhibit several qualitative features:

1) Where beliefs about two states of affairs, A and B, are related through a shared intuitive theory (e.g., A causes B), those beliefs will be systematically correlated across individuals (e.g. people who believe A will also tend to believe B); 

2) When two beliefs are related by an intuitive theory, evidence affecting one of those beliefs will also affect the other in accordance with their relationship in the intuitive theory (e.g. evidence for B will increase credence in A, and vice versa).

3) Thus, across individuals, the average change in one belief following evidence affecting another belief will be proportional to the correlation between those beliefs across individuals (e.g. evidence for B will increase credence in A in proportion to the correlation between beliefs A and B). 

Here, we sought to formalize this understanding of intuitive theories by representing an intuitive theory as a Bayesian network. Originally designed as tools for artificial intelligence [@pearl1988], Bayesian networks are a class of probabilistic graphical models that have been deployed widely across cognitive science [e.g. @gopnik.etal2004; @jern.etal2014; @griffiths.tenenbaum2005]. The heart of a Bayesian network is a graphical structure ---not unlike a "web of belief"---that represents variables as nodes connected by edges, where those edges represent probabilistic or statistical relations.

For example, the graph $\text{FIRE} \rightarrow \text{SMOKE}$ represents a Bayesian network capturing the understanding  that fire causes smoke. The example of cause and effect is especially intuitive, but edges in a Bayesian network need not be causal; they are better thought of as representing “influence relations,” which may also include relationships like logical implication and set membership [@williamson2001]. This influence relationship is represented as a probabilistic function, where the probability of smoke depends on the probability of fire. 

This model captures each of the qualitative features laid out above: First, it captures people’s  reasoning  about these states of affairs given observations: observing smoke would lead someone to infer that there is likely to be a fire, and observing fire would lead someone to predict smoke will soon follow (Feature 1). This model can also capture how these beliefs might covary across individuals: if two people hold different degrees of belief in FIRE, this model specifies the degree of belief each should have in SMOKE (Feature 2). Because the conditional probability of SMOKE given FIRE determines both the change in beliefs given observations and the correlation of beliefs across individuals, changes in beliefs following evidence will be proportional to their correlations across individuals (Feature 3). Formulating these features in a formal model, rather than a verbal theory, allows us to specify not just the presence but the quantitative strength of these relations, and to simulate the cumulative influences of many factors in more complex networks (for example, incorporating beliefs about the frequency of wildfires, recent weather conditions, etc.).    

Where the structure of an intuitive theory is known, Bayesian networks thus offer powerful tools for predicting and understanding how evidence will affect people's beliefs. However, there are many cases where the structure of the intuitive theory is itself the very question under investigation. Consider vaccine hesitancy: Earlier, we speculated that beliefs about the infant immune system and beliefs about the trustworthiness of the medical community (among many others) might affect people’s beliefs about vaccines. But the structure of the intuitive theory that might relate these beliefs is not at all clear. 

Fortunately, the formalism of Bayesian networks provides tools for navigating these challenges. Roughly, when the relationships among beliefs are unknown, we can use the qualitative features of intuitive theories to *infer* the structure of an intuitive theory from observed correlations among beliefs. Structure learning algorithms [see @scutari.denis2021] provide a means for searching through the (super-exponentially large) possible space of Bayesian networks to find the structure most likely to have generated some observed data. These approaches allow us to scale the Bayesian network modeling framework beyond the smaller models characteristic of early computational work on intuitive theories [e.g., @griffiths.tenenbaum2005].

## Current studies

Here, we used Bayesian network structure learning algorithms to construct a model of the intuitive theory underlying adults’ decisions about whether or not to vaccinate children against diseases like measles, mumps, and rubella.

In Study 1, we used Bayesian network structure learning algorithms to develop a cognitive model of the relationships among 14 beliefs related to vaccine hesitancy in a large sample of U.S. adults. In Study 2, we replicated the success of an existing intervention emphasizing the dangers of childhood diseases [@horne.etal2015] and used our model to provide a more detailed understanding of *how and why* this intervention increases vaccine intentions and its effects on related beliefs. In Study 3a and 3b, we drew inspiration from our model to create and validate the success of  a novel intervention aimed at addressing concerns about toxic additives in vaccines. Finally, in Study 4 we tested whether people's beliefs changed coherently following relevant real-world events, by examining beliefs before and after serious outbreaks of measles in the United States in early 2019. 

Taken together, this work illustrates the promise of understanding belief revision in terms of intuitive theories and the utility of discovering and formalizing intuitive theories via computational models. Of particular interest in the current moment, these findings lay a foundation for empirically-validated, theory-based educational interventions that could encourage people to vaccinate their children and themselves against dangerous diseases like measles and COVID-19.

# Study 1: Assessing and modeling intuitive theories of vaccination

Across all our studies, our primary outcome of interest was participants’ intentions to vaccinate their children against diseases like measles, mumps, and rubella (which we refer to henceforth as *vaccination intentions*). Drawing on a variety of sources, including research on anti-vaccine skepticism [e.g.,  @dube.etal2015; @larson.etal2015; @salmon.etal2015; @williams2014], anti-vaccine websites, and our own qualitative work with vaccine skeptics (see SI), we generated a list of 13 additional beliefs that, though surely not exhaustive, might jointly offer a reasonable means of understanding and predicting vaccine intentions.

We translated these qualitative insights into 14 psychometrically-valid scales. In addition to 1) _vaccination intentions_ (e.g. “If I had a young baby I would have him or her vaccinated.”), these included a variety of beliefs about vaccines, including beliefs about 2) _vaccine danger_, the overall danger of vaccines (e.g., “Many children have severe adverse reactions to the MMR vaccine”); 3) _toxic additives in vaccines_ (e.g., “Exposure to certain additives in vaccines can cause major health problems.”); and 4) _vaccine effectiveness_, how effective vaccines are in preventing disease (e.g., “Your chances of getting a disease after being vaccinated against it are incredibly low”); as well as a variety of specific claims about childhood diseases like measles, mumps, and rubella, including beliefs about 5) _disease rarity _(e.g., “Diseases like measles and whooping cough are so rare that there is no real need to worry about them”) and 6) _disease severity_ (e.g., “Diseases like measles and whooping cough are extremely dangerous for young children”). Beyond this, we theorized that participants’ understanding of the infant immune system might be relevant, including beliefs that 7) the infant immune system is weak (_IIS: weakness_; e.g., “Babies’ immune systems are weak”); 8) the infant immune system is limited in its capacity and can be easily overwhelmed (_IIS: limited capacity_; e.g., “Babies’ immune systems are severely limited in how much they can cope with at one time.”); and 9) vaccines strain the infant immune system (_IIS: vaccines strain_; e.g., “Vaccines strain the immune system much like the actual disease”). We also included general theories about parenting and medicine: 10) general _parental protectiveness_ (e.g., “Parents should strive to control their baby’s environments as much as possible”); 11) _parental expertise_, namely the belief that parents usually know more about their children’s health than medical experts (e.g., “Every individual is different and a parent knows their own child best”); and 12) _medical skepticism_, including concerns about pharmaceutical companies and corruption in the medical community (e.g., “Pharmaceutical companies put pressure on the FDA and CDC to suppress negative findings”); and two two broad worldviews: 13) _naturalism_, a general preference for natural over artificial things (e.g., “Natural things are always better than synthetic alternatives”); and 14) _holistic balance_, one important aspect of attitudes toward alternative medicine (e.g., “The body is essentially self-healing and the task of a health care provider is to assist the healing process”; [@mcfadden.etal2010]).

Each scale measured agreement with 4-6 statements, including at least one reverse-coded item, and was highly reliable (observed reliability, Study 1: all Cronbach’s $\alpha \geq .73$ .73). We developed 13 of these scales, and included one preexisting scale (the “holistic balance” subscale from [@mcfadden.etal2010]. See SI for all items included in all scales.

In Study 1, we administered these 14 belief scales to participants and in an online survey with `r results$s1$demo$n_include` participants. We then used these intercorrelations to build a cognitive model of the relations among these beliefs via Bayesian network structure learning techniques.

### Method

#### Participants

A total of `r results$s1$demo$n_total` people recruited from Amazon Mechanical Turk (mTurk) participated in this study conducted in August of 2017. Participants were paid \$1.60 for about 8 minutes of their time. `r results$s1$demo$n_exclude` participants (6%) failed at least one of two attention check questions and were excluded from further analysis, leaving a final sample of n = `r results$s1$demo$n_include`. See SI for demographic information about this sample.

#### Procedure

Participants (final *n* = `r results$s1$demo$n_include`) responded to the 14 belief scales. Each scale was presented on a separate survey page, and participants rated a series of statements on a 7-point scale from “Strongly disagree” (coded as -3) to “Strongly agree” (+3). Scales, and questions within each scale, were presented in a random order for each participant. Attention checks (e.g., “Please select somewhat agree”) were embedded within two to four randomly chosen scales and participants who failed any of these checks were excluded from analyses. We scored each belief scale by averaging a participant’s responses to each item (after reverse-coding where appropriate), then rescaling these values to fall between 0 and 1. We considered this score to represent the participant’s credence in the belief.
 
The 14 belief scales were followed by demographics questions and a handful of questions about whether participants were or were expecting to be a parent. Participants were then debriefed with a brief statement noting that vaccines are safe and pointing them toward a WHO website for further information. 

### Results

The goal of this study was to use these data to conduct a bottom-up search for a Bayesian network that would represent the intuitive theory surrounding vaccination decisions as a network of related beliefs. There were strong intercorrelations among these 14 beliefs confirming that these beliefs are, in fact, closely related to each other and to intentions to vaccinate children (see SI). Based on the observed associations among participants' beliefs about each of theses issues, we sought to infer how these states of affairs (e.g., that vaccines are dangerous, that diseases are severe) are connected in people's intuitive theories---how people understand these states of affairs to cause, imply, or otherwise influence one another. 

#### Bayesian network parameterization.

A Bayesian network is a directed acyclic graph that represents variables as nodes connected by directed edges. Each set of “child” and “parent” nodes in the larger network is a “family”. The network’s directed edges encode conditional dependencies among variables, and many parameterizations for the individual families are possible. In our model, the probability of some “child” belief node $y$ can be expressed as a noisy-logical function of the influence of one or more “parent” belief nodes $x$:

$$P(y) = \Big(1-(1-w_0)\prod_i(1-w_i)^{x_i}\Big)\prod_j(1-w_j)^{x_j}$$

Here, each parent node $x$ is either a generative ($i$) or preventive ($j$) influence, that generates or prevents the child node with some probability weight ($w_i$ or $w_j$). The weight $w_0$ represents the “leak” probability, or the baseline probability that the child occurs without any other generating influences. The first term represents the probability that $y$ is generated (or, put another way, that not all of the possible generating forces fail to generate it). The second term represents the probability that it is not then prevented [i.e., that all the preventing forces fail; see @maaskant.druzdzel2008].

Having transformed participants’ scores on each belief scale to fall between 0 and 1, we estimated the parameters of the model as a beta regression using maximum likelihood methods (see SI).

#### A cognitive model underlying the data model. 

We aimed to represent not only the relationships among variables in the data but the *cognitive model* that gave rise to these observed relationships, i.e., the relationships among beliefs in the mind. We actually estimated two models: First, we estimated a data model assuming that participants possess a shared mental model from which they generate their responses to the belief scales. In this model, the $x$ in the equation above corresponded to participants’ continuous responses to the belief scales (e.g. a participant's score for the *vaccine danger* scale). Then, from the parameters estimated in the data model we created a cognitive model of participants’ reasoning, where the $x$ are binary, indicating whether that state of affairs obtains (e.g., whether “vaccines are dangerous”). We used this cognitive model to simulate how beliefs could change following exposure to evidence.

#### Structure learning, constrained by a “generative model principle.” 

Rather than specifying a priori all of the connections among the 14 beliefs included in this study, we deployed Bayesian network structure learning to search for the most likely network structure given the observed correlations between beliefs---with the constraint that this structure conform to some of our strongest high-level intuitions about what an intuitive theory should look like in this domain.

In particular, we applied a constraint we called the “generative model principle,” based on the assumption that the intuitive theory is a generative model, so that these influence relations (“edges”) should flow from causes or other “generating” states of affairs toward effects. For instance, we stipulated that vaccine intentions---our outcome of interest---would be a “child node,” with edges only flowing inwards and not outwards (since one’s intention to vaccinate cannot “generate” the facts about vaccinations safety, effectiveness, etc). This generative model principle instills a common core assumption in research on intuitive theories and causal explanatory reasoning[e.g. @gerstenberg.etal2021; @gopnik.etal2004; @cheng1997]. 

To apply our generative model principle, we sorted the 14 measured beliefs into four tiers based on how general or abstract each belief was, reasoning that general and abstract states of affairs should be understood to cause (or otherwise generate) more specific and concrete states of affairs, so edges should flow from the general and abstract toward the specific and concrete (e.g., if natural things are better than artificial things, this should set an expectation about whether a specific class of artificial things--vaccines--is safe). We considered *holistic balance* and *naturalism* to be the most general and abstract beliefs among those we measured; followed by theories about parenting and medicine; then specific beliefs about vaccines, diseases, and the infant immune system; and finally our outcome of interest, *vaccine intentions*---the most concrete measurement of a specific intended action.

We used this sorting to induce a partial ordering of these 14 beliefs, stipulating that directed edges that violated this ordering must not appear in the final network of beliefs (e.g., that there should be no edge from *vaccine intentions* to *naturalism*, although there could be an edge from *naturalism* to *vaccine intentions*). 

To conduct an efficient search through the super-exponential space of graphs, we tested several learning algorithms implemented in the “bnlearn” R package [@scutari2010] and evaluated their performance through cross validation in our training split (see SI). Following this analysis, we chose to fit our model with the score-based “hill-climbing” algorithm, scoring models via the Bayesian Information Criteria, an asymptotic estimate of the likelihood of the data under a given graph structure. This produced the network shown in Figure 1. See SI for more detailed explanations of these modeling choices.



#### Structure learning 

To avoid overfitting, we used an 80% split of the data (*n* = 904) for training, and reserved the remaining 20% for evaluating model performance. Applying these techniques resulted in an estimate of the network shown in Figure 1. 

```{r fig1-maingraph, fig.align='center', out.width="90%", fig.cap="Bayesian network model resulting from hill-climbing algorithm with our generative-model constraints applied to data in Study 1 training split (n = 904). The network has 29 edges connecting these 14 variables. Edge polarity and weights are indicated by color, with red hues indicating negative or preventive influences, and blue hues indicating positive or generating influences. The direction of the edge was not determinable from the data and modeling constraints for two edges: $\\text{Naturalism} \\rightarrow \\text{Holistic Balance}$ and $\\text{Medical Skepticism} \\rightarrow \\text{Parental Expertise}$; see SI."}

knitr::include_graphics("../outputs/main-combined.pdf")
```

```{r, include=F}

avg_corr <- results$s1$validcorrs %>% 
  mutate(z = psych::fisherz(cor)) %>% 
  summarize(z = mean(z)) %>% 
  mutate(cor = psych::fisherz2r(z)) %>% 
  .$cor

min_corr <- round(min(results$s1$validcorrs$cor),3)
max_corr <- round(max(results$s1$validcorrs$cor),3)
```

We evaluated the model’s performance by testing its accuracy in predicting responses in the 20% testing split (*n* = 226). We generated predictions for held-out participants’ responses for each variable by conditioning the network on the remaining 13 observed variables. Figure 2 compares the model’s predictions with participants’ actual responses. Collapsing across all variables, the average correlation between predicted and observed responses was *r* = `r round(avg_corr, 3)`, accounting for `r round(100*avg_corr^2, 0)`% of the variance in observed responses.

```{r fig2-validation, fig.align='center', out.width="100%", fig.cap="Observed responses and model predictions for each belief among participants in the Study 1 testing split. Correlations between observed and predicted values ranged from .380 to .898 across the different belief scales. In general, the model showed greater predictive accuracy for more central beliefs (e.g., \\emph{vaccine danger}) than for more peripheral beliefs (e.g., \\emph{parental protectiveness}; see SI for details)."}
knitr::include_graphics("../local/valid_plt.png")
```

What does this model reveal about the intuitive theory underlying vaccination decisions? 

The three nodes with direct connections to *vaccine intentions* are beliefs about *vaccine effectiveness*, *vaccine danger*, and the severity of childhood diseases (*disease severity*) ---concrete beliefs that are, at face value, especially closely related to vaccination decisions.  This gives us confidence that the model is capturing important aspects of the intuitive theory of interest. 

Other parts of the model shed new light on the role of lay theories in vaccination decisions. For example, *naturalism* ---the general view that natural things are better than artificial things ---appears to be strongly related to *medical skepticism* and *parental expertise*; and all three of these abstract beliefs are related to concrete beliefs that, in turn, feed into participants’ vaccination intentions. 

This model structure also helps explain some initially surprising findings. For example, we originally speculated that dispelling misconceptions about the capacity of the infant immune system could promote positive attitudes toward vaccination. We were disappointed to observe the weak first-order correlation between this belief and *vaccine intentions* in our behavioral data (r = -.09 in our training split). The model sheds light on this surprising (lack of) relationship: Although the belief that the infant immune system is limited in capacity is positively related to the belief that vaccines strain the immune system---discouraging vaccination, as we had assumed---it also seems to promote the belief that childhood diseases have severe consequences for young children (*disease severity*), which might, in turn, encourage vaccination. These countervailing forces---which, on average, seem to have cancelled one-another out in this sample---dissuaded us from our plan to develop an intervention aimed at dispelling misconceptions about limited capacity in order to encourage childhood vaccination.

It is worth pointing out that not all of the relationships represented in the model should be interpreted as _causal_. Due to Bayesian networks’ tight connections with structural causal networks, it can be tempting to give the edges this interpretation, but in some cases these relationships are better thought of as probabilistic dependencies or “influence” relations (Williamson, 2001). For instance, intuitively we might imagine that vaccines having toxins (_toxic additives in vaccines_) could cause them to be dangerous (_vaccine danger_). These nodes are connected in the model, but the edges between them run in the opposite direction, and therefore do not support a clear causal interpretation. One interpretation is that this edge instead reflects a set membership relation; that toxins are one type of danger vaccines might present. 

In other cases, our data and explicit constraints do not perfectly identify the directions of the edges. This is the case for two edges (Naturalism $\rightarrow$  Holistic Balance and Medical Skepticism $\rightarrow$ Parental Expertise; see SI for details). In both cases, we do not feel it is intuitive which direction the edge should flow in, nor even that it should be directed at all; we might even speculate there is an additional unmeasured variable that connects these beliefs and that would best account for their association.

### Summary

From a set of potentially relevant beliefs and a general principle guiding the likely relationships among these beliefs, we generated a cognitive model of an intuitive theory of this domain. In Studies 2-4, we use this same model to predict how this intuitive theory guides reasoning about new information.  

## Study 2: Targeting disease severity beliefs

Very few educational interventions have been shown to improve attitudes toward childhood vaccination. One of the few successful educational interventions in this domain was tested by Horne and colleagues [-@horne.etal2015], who found that emphasizing the dangers of preventable diseases like mumps, measles, and rubella improved participants’ attitudes toward vaccines. Their intervention included descriptions of the symptoms of mumps, measles, and rubella; vivid photos of children suffering from these diseases; and a brief story from the perspective of a parent whose child was hospitalized with measles (see SI). This “disease risk” intervention improved attitudes toward vaccines compared to an irrelevant control essay and compared to an intervention aimed at debunking concerns about vaccines causing autism. In Study 2, we aimed to replicate this success and leverage the cognitive model developed in Study 1 to gain insight into how and why such an intervention successfully induces  belief revision in this domain.

In Study 2, we used the belief network established in Study 1 to predict how Horne and colleagues’ [-@horne.etal2015] intervention would affect the beliefs in this network, including people’s intentions to vaccinate their children. Participants completed the 14 belief scales from Study 1, then returned two days later to complete either the disease risk intervention or a no-intervention control, followed by the same 14 belief scales.

### Method

#### Participants.

We recruited `r results$s2$demo$n_recruited` people to participate in a two-day study via mTurk in April 2018. Two days later, participants who completed Phase 1 and passed attention checks were invited via email to participate in Phase 2 of the study, with `r results$s2$demo$n_recruited_post` participants returning (`r results$s2$demo$n_eligible` invited, retaining `r round(results$s2$demo$n_recruited_post/results$s2$demo$n_eligible*100, 1)`% of the Phase 1 sample). Participants were paid \$1.35 for their participation in each phase of the study. `r results$s2$demo$n_failed_post` participants (`r round( (results$s2$demo$n_failed_post/results$s2$demo$n_recruited_post)*100, 1)`%) failed at least one attention check on Phase 2 and were excluded from further analysis. We also excluded from analyses `r results$s2$demo$n_duplicate` additional participants who accessed the second survey more than once. This left a final sample of `r results$s2$demo$n_complete` participants.

#### Procedure

Procedures for Phase 1 of Study 2 were nearly identical to those of Study 1, but the debriefing statement was moved to the end of Phase 2. In Phase 2 (approximately two days later), participants completed a study very similar to Horne and colleagues' (2015) original intervention study. Participants were randomly assigned to either the disease risk condition or a no-intervention control condition, with the constraint that the distributions of participants’ Phase 1 *vaccine intentions* scores should be similar across the two conditions; we accomplished this by stratifying participants into three groups based on their pretest vaccine intentions, and randomly assigning them to conditions in equal numbers within each group. 

Participants (*n* = `r results$s2$demo$n_complete` passed attention checks in total) in the intervention conditions were presented with a version of Horne and colleagues'  “disease risk” intervention, modified to present subparts in a fixed (rather than randomized) order, with slight changes to wording to improve clarity, and with a final statement summarizing the take-home message of the intervention; see SI. They then completed the same 14 belief scales and demographic questions that they had completed in Phase 1. 

Participants in the no-intervention condition completed the belief scales and demographics questions without reading any material first.

### Results

Figure 3 shows the change in participants’ attitudes across all 14 belief scales, from pretest to posttest. As expected, the largest change was observed for *disease severity* beliefs---the belief directly targeted by the intervention. Most importantly, the disease risk intervention significantly increased participant’s *vaccination intentions*, conceptually replicating earlier findings regarding this intervention [@horne.etal2015]. 

```{r, include=F}
s2_reg <- summary(results$s2$reg)
```

We conducted a mixed-effects Bayesian ordinal regression to assess the effects of the disease risk intervention on responses to the *Vaccination Intentions* scale items, using the “brms” package for R [@burkner2017]. We regressed responses on phase (Phase 1 vs. 2, dummy-coded with Phase 1 as the baseline), condition (dummy-coded with the disease risk condition as the baseline, so as to assess difference scores in our condition of primary interest), and the interaction between phase and condition. We included random intercepts by subject and scale item. In this model, the unique effect of the intervention on vaccination intention scores is assessed by the interaction term (indicating the unique effect of Phase 2 for intervention versus no-intervention participants). The disease risk intervention increased participants’ vaccination intention ratings (interaction effect: $b$ = `r round(s2_reg$fixed[9,1],3)`, 95% CI: [`r round(s2_reg$fixed[9,3], 3)`, `r round(s2_reg$fixed[9,4], 3)`]). We consider this to be a full replication of Horne and colleagues' [-@horne.etal2015] results. See Figure 3, panel A.

Visual inspection of Figure 3, panel A, further reveals that changes were also observed across the belief network identified in Study 1. Not only did participants exposed to the intervention come to see childhood diseases as more severe, they also came to see vaccines as less dangerous, and demonstrated less medical skepticism as well as less commitment to “holistic balance”. These results suggest that targeted educational interventions could have wide-ranging effects, from influencing who people turn to for future information, to shaping the more abstract worldviews they bring to bear in understanding health and science.

```{r fig3-s2, fig.align='center', out.width="100%", fig.cap="Belief changes following the intervention in Study 2. Left, mean difference scores from pretest to posttest for the 14 belief scales across experimental conditions. Right, mean observed and model predicted change scores for the disease risk intervention condition. In both plots, error bars represent 95\\% confidence intervals. In both plots, changes were calculated after transforming responses to lie between 0 and 1."}

knitr::include_graphics("../local/s2_plt.png")
```

#### Modeling belief revision

How did this intervention---which focused solely on the dangers of childhood diseases---affect beliefs about *vaccine danger*, *medical skepticism*, *holistic balance*, and so on? One explanation is that this intervention provides direct evidence for *disease severity* beliefs and that other beliefs are revised as a result of their relationships with *disease severity* as captured in the intuitive theory. To examine this, we used the same model developed in Study 1 to simulate how the 13 other beliefs in the intuitive theory would change as a result of the intervention's direct effect on *disease severity* beliefs.

To model the effects of the intervention presented in Study 2 on the intuitive theory surfaced in Study 1, we augmented the belief network representing the intuitive theory with an additional node representing the information about measles, mumps, and rubella presented in the intervention. This evidence node was added as a child of the *disease severity* node, allowing the intervention to act as virtual evidence for *disease severity* [following @pearl1988]. 

To compute the conditional probability table (CPT) for this new node as a function of *disease severity* beliefs, we estimated an evidence ratio based on participants’ pretest and posttest credences in *disease severity*. To so do, we made use of the log-odds expression of Bayes rule, with the following regression equation:

$$logit(posttest) = logit(pretest) + \ln(ER_0) + x\ln(ER_{1})$$

Where *x* was a binary variable representing the presence (1) or absence (0) of evidence at posttest, and participants’ prior and posterior (pretest and posttest) credences were transformed into log odds. This allowed us to estimate the log evidence ratio implied by participants’ reactions to the intervention. Then, we constructed a CPT consistent with that evidence ratio. 

Using this augmented model, we are able to “condition” the model on this evidence node, and thereby predict how observing evidence will affect all of the beliefs in the network.  As shown in Figure 3, panel B, this simulation is a reasonable approximation of what we observed in Study 2: The model’s predictions correlate strongly with observed changes (*r* = `r results$s2$modcorr`). 

Given that our cognitive model is parameterized via noisy-logical functions, it should be noted that the marginal predicted influence of each belief is closely related to its first-order correlation with disease severity. This is in keeping with the qualitative features of intuitive theories we laid out in the introduction, and we should expect this to hold true (on average) for any plausible model of an intuitive theory. However, future models with more complex or nuanced parameterizations could potentially make additional predictions not evident from first-order correlations, such as individualized predictions for how individuals or groups would respond to evidence.

## Study 3a and 3b: Targeting beliefs about vaccine toxicity

The intervention developed by Horne and colleagues [-@horne.etal2015] and employed in Study 2 is notable for being one of the few educational interventions shown to decrease vaccine hesitancy---but is disease severity the only (or most) effective target for educational interventions in this domain? 

One advantage of having developed a formal, computational representation of a network of beliefs supporting vaccination decisions is that it can guide our search for effective interventions, allowing us to compare how interventions targeting each of these other beliefs might potentially change people’s vaccination intentions (see Figure 4). Countering myths about toxic additives is one approach the model developed in Study 1 predicts should be effective.

```{r fig4-predimpacts, fig.align='center',  out.width="50%", fig.cap="Predicted change in vaccination intentions following an equivalent hypothetical change in each of the other 13 beliefs."}
knitr::include_graphics("../local/pred_change_plt.png")
```

We developed a novel educational intervention that addresses fears about toxic additives in vaccines. This "vaccine ingredients" intervention explained the common components of vaccines, emphasized the minute quantities of all vaccine ingredients, and explained the roles that various vaccine additives play in ensuring the stability and safety of vaccines, such as antibiotics, adjuvants, and stabilizers. We gave special attention to defusing concerns about the use of formaldehyde in vaccines because our assessment of anti-vaccination websites suggested that this was a particular concern for many vaccine skeptics. The intervention acknowledged that some vaccines contain trace amounts of formaldehyde, but pointed out that formaldehyde is a metabolic byproduct that occurs naturally in all living things. The intervention highlighted that formaldehyde is already present in children’s bodies (and even in foods like pears) in far larger quantities than contained in any vaccine. The full intervention text is presented below.

> **"Vaccine ingredients" intervention text**\
> Vaccines are one of the most important medical advances in history, but some parents worry that vaccines contain toxins that could harm their babies. In fact, all of the ingredients in a vaccine serve important purposes that help ensure the safety and effectiveness of the vaccine. Decades of research have shown vaccine ingredients to be safe, even in much larger quantities than those found in vaccines.\
> **What’s in a vaccine?**\
> **Active ingredients**\
> The key ingredient in all vaccines is one or more active ingredients, whose purpose is to train the immune system to recognize and combat the pathogens that cause diseases. To do this, certain molecules from the pathogen are introduced into the body to trigger an immune response. These molecules are called antigens, and they are present on all viruses and bacteria. By injecting these antigens into the body, the immune system can safely learn to recognize them as hostile invaders, produce antibodies, and remember them for the future.\
>**Other Ingredients**\
> A typical dose of an injected vaccines is just 0.5 millilitres of liquid, which is just a few drops. Apart from active ingredients, the main ingredient in vaccines is water.  All other ingredients weigh a few thousandths of a gram or even less. All of the ingredients in vaccines have been proven to be safe for children in these minute quantities.\
> All of the ingredients in a vaccine serve important purposes, and are present to ensure that the vaccine is safe and effective. Some of these added ingredients are adjuvants, added to enhance the immune system response; others are antibiotics, to prevent contamination during the manufacturing process; and still other ingredients act as preservatives and stabilizers.\
> To take one example, consider one of the scariest things you may have heard about the ingredients in vaccines: that some vaccines contain formaldehyde. It may surprise you to learn that formaldehyde is actually produced by the human body as part of normal metabolic processes. Human bodies---even babies’ bodies---naturally produce, process, and safely excrete formaldehyde. The amount of formaldehyde in vaccines is extremely small compared to what our bodies produce on their own: the amount of formaldehyde naturally present in a 2-month-old infant’s blood (around 1.1 milligrams) is ten times greater than the amount found in any vaccine (less than 0.1 milligrams). In addition, many healthy foods--such as apples, grapes, bananas, and pears---naturally contain formaldehyde. A pear, for example, contains around 50 times more formaldehyde than is found in any vaccine.

### Methods

We conducted two preregistered experiments[^prereg] (Study 3a and Study 3b) testing the effects of this novel intervention aimed at dispelling concerns about toxic additives in vaccines using the same pretest-posttest design as Study 2. These studies followed similar design procedures as Study 2, with Phase 2 conducted 1-2 days after Phase 1. In both Study 3a (April 2019) and Study 3b (May 2019; combined final *n* = `r results$s3$demo$n_complete`) the vaccine ingredients intervention was compared against no-intervention control. Unlike Study 2, we did not stratify participants before random assignment to conditions. 

[^prereg]: https://osf.io/csnez/registrations

#### Participants.

We recruited `r results$s3$demo$n_recruited` people to participate in a two-day study via mTurk in April (Experiment 3A) and June (Experiment 3B) of 2019. One day after their initial participation, participants who completed part 1 and passed attention checks were invited via email to participate in Day 2 of the study, with `r results$s3$demo$n_recruited_post` participants returning (`r results$s3$demo$n_eligible` invited, retaining `r round(results$s3$demo$n_recruited_post/results$s3$demo$n_eligible*100,1)`% of the Day 1 sample). Participants were paid \$1.35 for their participation in each phase of the study and were allowed to participate in part 2 up to two days after their initial participation in part 1. `r results$s3$demo$n_failed_post` participants (`r round( (results$s3$demo$n_failed_post/results$s3$demo$n_recruited_post)*100,1)`%) failed at least one attention check on Day 2 and were excluded from further analysis.  This left a final sample of `r results$s3$demo$n_complete` participants. See SI for demographic information about this sample.

#### Procedure

Procedures for Studies 3a and 3b closely followed those of Study 2, but these studies tested the effects of a novel intervention aimed at dispelling concerns about toxic additives in vaccines. In both studies, participants were randomly assigned to either a no-intervention control condition or to the novel "vaccine ingredients" intervention.

### Results

#### Regression analyses. 

```{r, include=F}
s3_reg <- summary(results$s3$reg)
```

As they shared the same design, we combined data from Studies 3a and 3b for analysis (but see SI for separate analyses by study). As in Study 2, we conducted a mixed-effects Bayesian ordinal regression to assess the effects of the vaccine ingredients intervention on participants’ *vaccination intentions* scores. The vaccine ingredients intervention improved participant’s vaccination intention scores relative to the control conditions (interaction effect: $b$ = `r round(s3_reg$fixed[9,1],3)`, 95% CI: [`r round(s3_reg$fixed[9,3], 3)`, `r round(s3_reg$fixed[9,4], 3)`]); see Figure 5, panel A. It is worth noting that reliable changes were also observed from pretest to posttest in the control conditions (phase effect: $b$ = `r round(s3_reg$fixed[7,1],3)`, 95% CI: [`r round(s3_reg$fixed[7,3], 3)`, `r round(s3_reg$fixed[7,4], 3)`]), suggesting that these attitudes were also being influenced by other factors during the course of the study. We discuss this further below, but given that these studies were randomized controlled trial designs, these findings do not impair our ability to conclude that the intervention was causally efficacious in affecting vaccine intentions.

#### Modeling belief revision

To model the effect of the vaccine ingredients intervention, we followed the same procedure as in Study 2, but this time augmented the model with a node representing the vaccine ingredients intervention as a child of the vaccine toxins belief node (for details, see SI). This allowed us to predict how other beliefs in the network would change in light of the observed changes participant’s beliefs about whether vaccines contain dangerous toxins; see Figure 5, panel B.

Collapsing across these two studies, Figure 5 shows the change in participants’ (*n* = `r results$s3$demo$n_complete`) attitudes across all 14 belief scales from pretest to posttest. Most importantly, the vaccine ingredients intervention significantly improved participants’ vaccination intentions compared to the no-intervention control condition. Changes were also evident across many of the 14 beliefs, with the largest changes being a reduction in vaccine toxicity beliefs. 

```{r fig5-s3, fig.align='center',  out.width="100%", fig.cap="Belief changes following the intervention in studies 3a and 3b. Left, mean difference scores from pretest to posttest for the 14 belief scales across experimental conditions. Right, mean observed and model predicted change scores for the disease risk intervention condition. In both plots, changes were calculated after combining data from both studies and transforming responses to lie between 0 and 1 and error bars represent 95\\% confidence intervals."}
knitr::include_graphics("../local/s3_plt.png")
```

As in Study 2, we used our model to predict how the 13 other beliefs in the intuitive theory should be expected to change given the average magnitude of the change observed in participants’ vaccine toxicity beliefs following the intervention. As shown in Figure 5, the model’s predictions are significantly related to the observed changes, but the correlations are relatively weaker (*r* = `r results$s3$modcorr`) than those observed in our other studies. 

In Study 3a, we were surprised to observe that beliefs also changed significantly from pretest to posttest among participants in the no-intervention control condition. Two months later we conducted a direct replication (Study 3b) in the hopes that any transient factors that might have caused these changes in beliefs might have dissipated, but we obtained very similar results (see SI). 

We speculate that changes from pretest to posttest among control participants in both experiments were related to media coverage of measles outbreaks in the U.S. during the time these studies were conducted (April and June of 2019), so that participants’ beliefs were not only affected by our intervention between pretest and posttest, but also potentially by additional news stories or social media content related to the outbreaks. As we employed a pretest-posttest design and randomly assigned participants to conditions, these changes do not impair our ability to draw causal inferences as to the efficacy of our intervention. However, these additional unmodeled influences may be negatively impacting performance of the model’s predictions.

Nevertheless, the success of this intervention in changing people’s responses to our *vaccine intentions* scale highlights the potential of this computational, theory-based approach to understanding belief revision. This model allowed us to design a novel educational intervention focusing on vaccine ingredients that successfully changed participants’ beliefs in a domain where many previously-researched educational approaches have failed---while sparing the time and resources we might have otherwise expended on interventions which our model predicts are unlikely to be successful. 

## Study 4: Natural experiment

The early months of 2019 saw the worst U.S. measles outbreak in decades, with over 1000 cases reported by June, mostly in the state of New York. These outbreaks were covered in every major newspaper and by every major news program. Would learning about these tragic events lead people to revise their beliefs about vaccines?

```{r fig6-s4, fig.align='center',  out.width="100%", fig.cap="Participants’ belief changes from participation in Study 1 to Study 4. Left, mean difference scores comparing beliefs reported in August-September 2017 and May 2019 for the 14 belief scales, across participants who did and did not report exposure to news of the ongoing New York measles outbreak. Right, mean observed and model predicted change scores for those participants who did report exposure to this news. Belief changes were modeled assuming that news of the outbreak directly impacted participant's vaccine intentions, the most central of the 14 beliefs, in order to evaluate the overall coherence of these belief changes. In both plots, changes were calculated after transforming responses to lie between 0 and 1 and error bars represent 95\\% confidence intervals."}
knitr::include_graphics("../local/s4_plt.png")
```

### Methods

To examine this possibility, we invited participants from Study 1 (conducted in August-September 2017) to participate in a new study measuring each of those 14 beliefs again (conducted from May 1st to 3rd, 2019; approximately 18 months later). Of the `r results$s1$demo$n_include` participants in Study 1, a total of `r results$s4$demo$n_recruited` participants returned and `r results$s4$demo$n_complete` successfully completed the study, including passing attention checks. Approximately `r round(100*(results$s4$demo$n_news/results$s4$demo$n_complete),0) `% of participants reported recently seeing, hearing, or reading about measles outbreaks. See SI for demographic information about this sample.

### Results and discussion

Figure 6, panel A, shows the average change in participants’ beliefs following the outbreaks of 2019. Among participants who were exposed to relevant news covered, we observed changes in a number of beliefs, with notable increases in intentions to vaccinate, perceptions of vaccine efficacy, and perceptions of disease severity, as well as notable decreases in concern about vaccine danger. In contrast, most beliefs remained unchanged for those participants who did not report exposure to media, although there were modest changes in their beliefs about disease severity and disease rarity. These outbreaks appear to have significantly impacted people’s beliefs surrounding vaccination.

```{r, include=F}
s4_reg <- summary(results$s4$reg)
```

Mirroring our analyses of interventions, we regressed responses to the *vaccine intentions* scale items on predictors for phase (August-September 2017 vs. May 2019, dummy-coded), news exposure (dummy-coded with non-exposure as the baseline), and an interaction between phase and news exposure onto participants’ scores, using a Bayesian mixed-effects ordinal regression including random intercepts by subject and item. To assess the effects of recent news exposure on vaccine intentions, we examined the interaction between phase and news exposure. Participants’ vaccine intentions were increased by recent news exposure compared to their responses 18 months earlier (interaction effect: $b$ = `r round(s4_reg$fixed[9,1],3)`, 95% CI: [`r round(s4_reg$fixed[9,3], 3)`, `r round(s4_reg$fixed[9,4], 3)`]); see Figure 6, panel A. 

#### Modeling belief revision

Were changes in participants' beliefs following exposure to news of the measles outbreak coherent with respect to the intuitive theory specified by the model developed in Study 1? Unlike in the intervention studies, where a specific belief was targeted by the intervention, it is likely that many beliefs were addressed by media coverage of these outbreaks. To assess whether these changes were coherent, we examined how they were related to the most central of the beliefs we measured, *vaccine intentions*, using our model to predict how the 13 other beliefs in the intuitive theory should be expected to change given the average magnitude of the change observed in *vaccine intentions.* That is, we followed the same procedure as in previous studies, but here augmented the model with a node representing media exposure as a child of the *vaccine intentions* node. 

As shown in Figure 6, panel B, the changes in participants’ beliefs are very similar to the model’s predictions (*r* = `r results$s4$modcorr`), suggesting that the changes in their beliefs were highly coherent with respect to their intuitive theories of the domain. Modeling these beliefs as united by an intuitive theory not only captures how these beliefs are revised immediately in light of evidence, but also how they are changed by real-world events.  

# Discussion

Across five studies, we examined how understanding people’s intuitive theories surrounding vaccination decisions could help us formulate educational interventions that would counteract misconceptions about vaccine safety and encourage vaccination. We identified 14 beliefs related to vaccination decisions and captured the relationships among these beliefs in a generative probabilistic cognitive model. Using this model we were able to predict how these beliefs would be affected by controlled educational interventions as well as real-world events. Inspired by our findings and model, we developed an intervention targeting beliefs about toxins in vaccines and found it successfully increased people’s intentions to vaccinate their children---adding to the very short list of effective interventions in this domain.

Our findings indicate that beliefs related to vaccination decisions can be understood as situated within a coherent intuitive theory: these beliefs were systematically related across individuals (Study 1), and these relationships were predictive of changes across these beliefs following evidence, whether that evidence took the form of educational interventions (Studies 2, 3a, 3b) or real-world events (Study 4). Modeling this intuitive theory formally as a Bayesian network allowed us to create a cognitive model that demonstrates these key features of intuitive theories quantitatively. Looking forward, this formal representation ---though simplified and imperfect---lays a foundation for richer and more complex descriptions in the future. For instance, networks with richer parameterizations could capture how intuitive theories differ across individuals, opening up the possibility of fine-tuning predictions and perhaps even crafting tailored educational interventions for specific individuals or groups.

Developing this model also had practical benefits. By providing a graphical representation of the structure of this intuitive theory, this approach helped us to understand relationships between beliefs that were puzzling when considered only as correlations (e.g., the lack of correlation between beliefs about the infant immune system and vaccine intentions), and allowed us to “spot” opportunities to develop novel interventions. 

More broadly, the approaches we have introduced here may shed light on long-standing theoretical questions about belief revision. Many researchers have argued that people's belief updating is subject to various biases, or is skewed by motivational factors [e.g. @kahan2013; @flynn.etal2017; @kunda1990]. Yet many of the phenomena traditionally taken as evidence for these theories can also be explained by normative models of belief revision, so long as we are willing to posit that other auxiliary beliefs can affect the relationships between a belief and evidence [e.g.,@gershman2019; @jern.etal2014]. Adjudicating between competing views of belief revision will require us to move beyond minimal models and illustrative simulations by assessing whether people actually do hold these auxiliary beliefs, and whether their broader belief systems behave according to the rules of probabilistic inference. The Bayesian network structure learning techniques applied here are one tool we might use to build these richer models. 

## Implications for and insights from the COVID-19 pandemic

Though these studies were conducted before the onset of the COVID-19 pandemic and focused on childhood diseases, many similar concerns are likely to animate hesitancy toward COVID-19 vaccines, and our findings may provide some leverage into addressing the current surge of vaccine hesitancy.

First, in the spirit of Horne and colleagues’ [-@horne.etal2015] disease risk intervention, we suspect that education focused on how severely ill many people become and the prevalence of long-term health problems following even mild cases of COVID-19 might encourage people to accept coronavirus vaccines. Indeed, controlled intervention studies have shown that messages focused on personal risk increase vaccination intentions [@motta.etal2021]. However, as the pandemic has continued, it has become clear that the severity of COVID-19 is highly variable across individuals and across variants of the virus, potentially rendering the formation, updating, and use of beliefs about severity much more nuanced in the case of COVID-19 than in the case of diseases like measles. 

Our findings also suggest that beliefs about vaccine efficacy are central to determining vaccination intentions. In the case of mumps, measles, and rubella, strong vaccines and robust vaccination campaigns have led to the near eradication of these diseases in the U.S. and other developed nations. Correspondingly, we observed most participants in our studies believed quite strongly that these vaccines are effective in preventing infection. In contrast, the high prevalence of COVID-19 makes the risk of infection substantial even for the vaccinated, although these vaccines remain highly effective at preventing severe illness and death. The rising prevalence of breakthrough infections and the need for boosters relatively soon after initial doses are likely to lead people to doubt the effectiveness of vaccines---but we see promise in educational interventions that clarify the many ways in which a vaccine can be “effective” (e.g., by preventing infection vs. by preventing severe illness, preventing death, or lowering transmissibility), or explain the need for booster shots (e.g., addressing the misconception that the need for a booster shot indicates a problem with the vaccine).

Looking forward, living through the COVID-19 pandemic is likely to have deepened the public’s understanding of infectious diseases and public health. For example, the concept of “herd immunity” has likely never had greater public understanding and appreciation than now. This understanding seems like a prime target for future interventions aimed at increasing the uptake of vaccines for both COVID and other diseases—although its impacts are likely to depend on other auxiliary ethical commitments, such as moral beliefs about individuals’ obligations to their wider communities.

Unfortunately, the scale and spread of dis- and misinformation about COVID-19 has far eclipsed the spread of fringe ideas about MMR vaccines: millions of people have come to believe that COVID-19 is caused by 5G telecommunications, that the virus was developed in a lab to be used as a bio-weapon, or even that the virus is not real at all, and instead is a "hoax" perpetrated by a globalist elite. As is the case with attempts to debunk the misconception that childhood vaccines cause autism, directly addressing these false conspiracy theories could prove to be extremely difficult. However, there is some cause for hope that clear education about COVID-19 vaccines may help to address these misconceptions indirectly. Our findings demonstrate that revising beliefs about  specific diseases or vaccines can have “upstream” consequences for more abstract beliefs, such as naturalism and medical skepticism—hinting at a novel approach for addressing the kinds of fringe theories that have emerged during the pandemic.

Finally, like all pandemics, the COVID-19 pandemic is inescapably social. For one, in the U.S. and abroad, COVID-19 vaccines and mitigation measures have become deeply politicized. According to Gallup polling in the U.S., COVID-19 vaccination rates have at times been nearly twice as high among Democrats as among Republicans [@gallup2021]. Messages from political elites often imply concrete beliefs about the world that could be incorporated into a model of an intuitive theory: for instance, that COVID-19 is "like the flu" or that infection can be treated with off-label pharmaceuticals—or, conversely, that COVID-19 vaccines are safe and effective. Still, these affiliations are also associated with social commitments and personal values that may behave differently than the beliefs examined here. Whereas beliefs about “matters of fact” might be driven by an underlying intuitive theory and thereby sensitive to evidence, these sorts of identity-constituting “beliefs” may operate by different principles [@vanleeuwen2014] or may be entirely socially-motivated [@kahan2016].

More broadly, people from different social groups have different experiences and knowledge that are likely to shape their intuitive theories of vaccination and the medical establishment in important ways—something that the approach we have taken in the current studies does not yet account for. For example, White vs. Black Americans are likely to have different experiences with medical racism. Future work should explore how differences in people’s wider intuitive theories might explain vaccination behaviors, as well as how a more nuanced understanding of these theories might support messages tailored to different individuals and communities.

## Conclusions

Intuitive theories are powerful cognitive tools, for better and for worse. Coherent networks of beliefs allow people to understand, predict, and navigate the world, but they can also sustain misconceptions and lead to suboptimal---even dangerous---decisions and behaviors. As the past two years have made abundantly clear, deciding to opt out of getting vaccinated against diseases like measles or COVID-19 is not only dangerous for the individual, but a serious threat to public health. We hope the studies presented here have shed light on how people might come to such decisions, why the misconceptions that support these decisions can be so hard to combat, and how to develop educational interventions that are persuasive and effective in encouraging and sustaining healthier behaviors.

\newpage
# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
