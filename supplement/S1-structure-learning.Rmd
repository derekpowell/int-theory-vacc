---
title: "Vaccine data modeling: Custom MCMC solution"
output: 
  html_notebook: 
    code_folding: hide
---

In this notebook I'll do all the modeling for study 1. I will use my custom scoring method with BiDAG to do MCMC search for a structure across the space of DAGs. I'll do a few searches, imposing different top-down theory/constraints. In each case, we'll inspect the MAP dag and the posterior probability of edges.

My approach will be to searching for an underlying cognitive model. For each family, the responses are treated as generated from a cognitive model, as reports of the credence in the states of affairs represented by each variable.

Unpacking that a bit more, the idea is that participants share a mental model of some set of states of affairs (SOAs), that is, how the states of affairs relate or go together. The relations between SOAs can be represented by conditional probability table. To estimate this CPT, I further assume these CPTS can themselves be captured by a canonical distribution--in this case, something I'm calling noisy-or-nor (needs a better name). Noisy-or-nor assumes that each parent has an __independent__ generating or preventing influence on the child node. The probability of the child is the probability that it is generated (either by one of its generating parents, or a implied "leak" variable) and that none of its preventers prevent it. This is based on work by Lu & Yuille, and draws on a common set of assumptions in causal learning literature. The essential feature of this CPD is that __it assumes independent influences of each parent on the child__--this is necessary in order to estimate the parameters of the CPD from reports of the marginal probability of each SOA.

```{r}
source("../code/load-data-s1.R", chdir = TRUE)
```

```{r}
# detach("package:BiDAG", unload=TRUE)

library(tidyverse)
library(BiDAG)
# BiDAG depends on 'graph' package, source: http://www.bioconductor.org/packages/release/bioc/html/graph.html
# BiDAG depends on 'RBGL' package, source: https://bioconductor.org/packages/release/bioc/html/RBGL.html
library(bnlearn)
library(HydeNet)
library(gtools)

source("../code/custom-structure-learning/cog-model-main.R", chdir = TRUE)
source("../code/graph-model-tools.R")
source("../code/custom-structure-learning/cog-model-jags-tools.R")
source("../code/helpers.R")

# # customize BiDAG functions
# orig_DAGcorescore <- BiDAG:::DAGcorescore # save to switch back if desired
# orig_TableDAGscore.alias <- BiDAG:::TableDAGscore.alias # save to switch back if desired


```

# Set up data

Participants responses were scaled from a 1 to 7 rating scale onto the open interval (0,1). We scaled these responses as recommended by [cite beta regression paper]. After scaling, we interpret these responses as indicating participants' credence in each belief--that is, the marginal probability they assign to the state of affairs described by the scale.

```{r}
# rescale beta

d_bn_scaled <- d_bn %>%
 mutate_all(function(x){rescale_beta(x,-3,3)})

## set the seed to make your partition reproductible
set.seed(123)
trainInd <- sample(seq_len(nrow(d_bn_scaled)), size = floor(nrow(d_bn_scaled)*.80))

train <- d_bn_scaled[trainInd, ]
test <- d_bn_scaled[-trainInd, ]
```

## Define search spaces

Initialize search space. Perform initial pruning of search space using PC algorithm. This step does not respect cognitive model assumptions. Generally, this is a heuristic step needed to get the process off the ground.

In addition to the basic level of streamlining needed, we also impose different "blacklists" to constrain the search according to theory. These different blacklists apply our "generative model" assumption with different degrees of specificity. This can (might?) help us probe where our assumptions are driving findings, versus the kinds of findings that are emerging directly out of the data.

```{r}
# run to compute scoretables
# takes a few minutes if not computing scoretables ...
# takes a long time (10 hours ish) if scoretables must be computed ...

compute_scoretables <- FALSE # uncomment to recompute scoretables
source("../code/custom-structure-learning/fit-cog-models.R", chdir=TRUE)

```


```{r}
nCores <- parallel::detectCores(logical=TRUE)

# load scoretables computed by fit-cog-models.R

scoretables <- list(
  readRDS("../local/scoretable-unconstrained.rds"),
  readRDS("../local/scoretable-intent_is_dv.rds"),
  readRDS("../local/scoretable-abstract_are_parents.rds"),
  readRDS("../local/scoretable-abstract_are_parents_intent_dv.rds"),
  readRDS("../local/scoretable-theoryBasedHierarchy.rds")
  )

# # DO MCMC - comment to skip and load saved results
# all_results <- list(list(), list(), list(), list(), list())
# 
# customize_BiDAG() # customize bidag!
# 
# for (i in 1:length(startspaces)) {
#   all_results[[i]] <- parallel_orderMCMC(train,
#                                        startspaces[[i]],
#                                        scoretables[[i]],
#                                        MAP = FALSE, # might error
#                                        1e6,
#                                        100,
#                                        blacklist = blacklists[[i]],
#                                        chains = 4,
#                                        cores = 4
#                                        )
# 
# }
# 
# reinit_BiDAG() # set it back!

# saveRDS(all_results, "allresults.rds")

all_results <- readRDS("../local/allresults.rds")
```

## For all four

Now let's do this for all five models ...

```{r}

plots <- list()
all_edge_df <- data.frame()

for (i in 1:5) {
  chains <- all_results[[i]]
  merged_chain <- merge_chains(chains)
  map_dag <- extract_mapdag(merged_chain)
  
  h <- HydeNetwork(as.formula(bnlearn_to_hyde_string(map_dag)))
  plots[[i]] <- plot(h)
  
  edge_posterior <- edges.posterior(merged_chain$incidence, pdag=FALSE)
  rownames(edge_posterior) <- nodes
  colnames(edge_posterior) <- nodes 

  edge_df <- reshape::melt(edge_posterior) %>%
    rename(x = X1, y = X2) %>%
    mutate(constraints = i)
  all_edge_df <- bind_rows(all_edge_df, edge_df)
}


```

NOTE: chains did not converge for #2, intent as DV ...

```{r}
print("unconstrained")
plots[[1]] # intent is dv
print("intent is dv")
plots[[2]] # intent is dv
print("hb + naturalism are parents")
plots[[3]] # hb + naturalism are parents
print("hb + naturalism are parents, intent is dv")
plots[[4]] # hb + naturalism are parents, intent is dv
print("full abstraction hierarchy")
plots[[5]] # full abstraction hierarchy
```

```{r, fig.align="center", fig.width=8, fig.height=8}
all_edge_df %>%
  mutate(constraints = factor(constraints, 
                              levels = c(1,2,3,4,5), 
                              labels = c("unconstrained",
                                "intent is dv", 
                                         "hb + nat are abstract", 
                                         "intent is dv\nand hb+nat are parents", 
                                         "theory based"))
         ) %>%
  ggplot(aes(x=x, y=y, fill=value)) +
  geom_tile() +
  facet_wrap(~constraints) +
  scale_fill_viridis_c(option="C") +
  theme_minimal() +
  theme(aspect.ratio=1) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=.5)) +
  labs(x = "From", y = "To", title="Edge posterior probabilities", fill="p(edge)") 
```

Comparing posteriors ...

The code below can be used to compare the posterior edge probabilities under different constraints. It's still a bit tricky to get a sense of, but this gives the answer more or less ...

```{r}
all_edge_df %>%
  spread(constraints, value) %>%
  mutate(diff = `2`-`1`) %>% # which to compare ...
  ggplot(aes(x=x, y=y, fill=diff)) +
  geom_tile() +
  # facet_wrap(~constraints) +
  scale_fill_viridis_c(option="C") +
  theme_minimal() +
  theme(aspect.ratio=1) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=.5)) +
  labs(x = "From", y = "To", title="Edge posterior prob. diffs", fill="prob. diff") 
```


## Impressions

workign?

# Focusing in ...

Using theory-based model ...

Extract results and plot a traceplot. For unconstrained search, chains did not all converge

```{r}

BiDAG_traceplot(all_results[[5]], hide = 1, show_chains=c(1,2,3,4))
# BiDAG_traceplot(all_results[[3]], hide = 100, show_chains=c(3,4))
```

plot map dag 

```{r}
merged_chains <- merge_chains(all_results[[5]][1:4])
map_dag <- extract_mapdag(merged_chains)

h <- HydeNetwork(as.formula(bnlearn_to_hyde_string(map_dag)))
plot(h)
```

plot posterior

```{r}
edge_posterior <- edges.posterior(merged_chains$incidence, pdag=FALSE)
rownames(edge_posterior) <- nodes
colnames(edge_posterior) <- nodes 

edge_df <- reshape::melt(edge_posterior) %>%
  rename(x = X1, y = X2)

edge_df %>%
  ggplot(aes(x=x, y=y, fill=value)) +
  geom_tile() +
  scale_fill_viridis_c(option="C") +
  theme_minimal() +
  theme(aspect.ratio=1) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=.5)) +
  labs(x = "From", y = "To", title="Edge posterior probabilities", fill="p(edge)") 
```

## Predictions

Now we do one-node held-out prediction as I have in the past. 

```{r}
# this now takes ~20 minutes or so
model_string <- suppressWarnings(write_jags_model(map_dag, train))
cat(model_string)
```

```{r}
# #  takes about 20-30 min to run

# start_time <- Sys.time()
# 
# # test2 <- test
# predictions <- test %>% mutate_all(function(x){NA}) %>% mutate_all(as.numeric)
# # net.fit <- bn.fit(map_dag, train)
# 
# for (targVar in names(test)) {
#   tempDF <- test
#   tempDF[[targVar]] <- NA
#   tempDF[[targVar]] <- as.numeric(tempDF[[targVar]])
#   
#   # imputed <- impute(net.fit, tempDF, method="bayes-lw")
#   imputed <- make_predictions(model_string, test, nodes_to_predict = targVar)
#   predictions[[targVar]] <- imputed[[targVar]]
# }
# 
# predictions <- predictions %>% gather(varName, predValue)
# test_analyze <- test %>% gather(varName, value) %>% bind_cols(predictions) %>% select(varName, value, predValue)
# 
# print(Sys.time() - start_time)

# saveRDS(object = test_analyze, file = "../local/s1_model_predictions.rds")

test_analyze <- readRDS("../local/s1_model_predictions.rds")
```


# job talk plots

November 16, 2018

## predicted vs observed across scales

```{r}
library(ggthemes)

recode_nodes <- function(x){
  recode(x,
         "diseaseRare" = "Disease Rarity",
         "diseaseSevere" = "Disease Severity",
         "hb" = "Holistic Balance",
         "infantImmLimCap" = "IIS: Limited\nCapacity",
         "infantImmWeak" = "IIS: Weakness",
         "medSkept" = "Medical\nSkepticism",
         "nat" = "Naturalism",
         "overpar" = "Parental\nProtectiveness",
         "parentExpert" = "Parental\nExpertise",
         "vaccDanger" = "Vaccine\nDanger",
         "vaccEff" = "Vaccine\nEffectiveness",
         "vaccIntent" = "Vaccination\nIntentions",
         "vaccStrain" = "IIS: Vaccines\nStrain",
         "vaccTox" = "Vaccines\nToxicity")}

predObsCor <- cor(test_analyze$value,test_analyze$predValue)

corrDF <- test_analyze %>%
  # mutate(varName = recode_nodes(varName)) %>%
  group_by(varName) %>%
  summarize(cor = cor(value,predValue)) %>%
  mutate(cor = format(round(cor,2),nsmall=2))

plt.valid <- test_analyze %>%
  mutate(varName = recode_nodes(varName)) %>%
  ggplot(aes(x=predValue, y=value)) + 
  geom_abline(slope=1, intercept=0, linetype="dashed", alpha=.33) +
  geom_point(shape=1, size=.5, color="darkturquoise") + 
  geom_text(data=corrDF, aes(label=paste("r =", cor)),
            x=-Inf, y=Inf, hjust=-0.12, vjust=1.4,
            size = 10*.352777778,
            color="grey25") +
  # geom_smooth(method="lm") +
  coord_fixed() + 
  facet_wrap(~varName, nrow=2) + 
  scale_x_continuous("Predicted values", limits = c(0, 1)) +
  scale_y_continuous("Observed values", limits = c(0, 1)) +
  theme_bw(base_size = 10) +
  theme(strip.background = element_rect(fill="grey90"), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

ggsave(plot = plt.valid, filename = "../local/s1_predobs_plot.png", width=8.5, height=4)
```

## network structure (beautified)

```{r}
# do network structure plotting here ...
library(DiagrammeR)

custom_plot.HydeNetwork <- function(x, 
                             customNodes = NULL,
                             customEdges = NULL,
                             ..., 
                             removeDeterm = FALSE,
                             useHydeDefaults = TRUE)
{
  if (removeDeterm) x <- plot_nondeterm_only(x)
  
  node_df <- 
    DiagrammeR::create_node_df(n = length(x[["nodes"]]),
                               label = x[["nodes"]])
  # 
  # node_df <- data.frame(nodes = x[["nodes"]],
  #                       stringsAsFactors = FALSE)
  if (useHydeDefaults) node_df <- HydeNet:::mergeDefaultPlotOpts(x, node_df)
  
  if (!is.null(customNodes)) node_df <- HydeNet::mergeCustomNodes(node_df, customNodes)
  
  edge_table <- do.call("rbind", 
                        mapply(FUN = HydeNet:::mapEdges, 
                               x[["nodes"]], 
                               x[["parents"]],
                               MoreArgs = list(node_df = node_df)))
  
  edge_df <- DiagrammeR::create_edge_df(from = edge_table[, 2], 
                                        to = edge_table[, 1])
  
  if (!is.null(customEdges)) HydeNet::mergeCustomEdges(edge_df, customEdges)
  
  
  
  DiagrammeR::create_graph(nodes_df = node_df,
                           edges_df = edge_df,
                           attr_theme = NULL)
  
}


## ----------------------------------------

# code to demo. For some reason set_edge_attrs() isn't working right, so have to do it manually

map_to_viridis <- function(vec, bins=64, option="D"){

  binned <- cut(vec, bins)
  levels(binned) <- viridis::viridis(bins, option=option)
  
  return(as.character(binned))
}


map_to_brewer <- function(vec, bins=11, option="RdYlBu"){
  binned <- cut(vec, bins)
  levels(binned) <- RColorBrewer::brewer.pal(bins, name=option)
  
  return(as.character(binned))
}

```


```{r}
z <- custom_plot.HydeNetwork(h)

c <- find_dag_coefs(map_dag, train)

coefs <- tidy_coefs(c)

coefs %>%
  filter(parameter!="phi",parameter!="w_leak") %>%
  rename(from = parameter) %>%
  mutate(from = gsub("w_","",from)) %>%
  select(to, from, value) %>%
  merge(z$nodes_df %>% rename(from = label) %>% select(id, from), by="from") %>%
  mutate(from = id) %>%
  select(-id) %>%
  merge(z$nodes_df %>% rename(to = label) %>% select(id, to), by="to") %>%
  mutate(to = id) %>%
  arrange(to,from) -> edge_df_mod
  # select(value, id.x, id.y) %>%
  # mutate(from = id.x, to = id.y)

# z$nodes_df
z$nodes_df <- z$nodes_df %>% mutate(label = recode_nodes(label))
z$nodes_df$fontname <- "Helvetica"
z$nodes_df$shape <- "ellipse"
z$nodes_df$fillcolor <- ifelse(z$nodes_df$id==13, "grey","white")
z$nodes_df$fixedsize <- FALSE
z$edges_df$penwidth <- abs(edge_df_mod$value)*2
z$edges_df$penwidth <- 1.5
# z$edges_df$label <- round(edge_df_mod$value,2)
# z$edges_df$color <- ifelse(edge_df_mod$value > 0, "blue","red")
z$edges_df$color <- map_to_brewer(edge_df_mod$value)
render_graph(z)

```

# save relevant outputs!

```{r}
# save model as bn
saveRDS(map_dag, "../local/map_dag_bn_theorybased.rds")
# and as hydnet
saveRDS(h, "../local/map_dag_hydenet_theorybased.rds")
# save model string
saveRDS(model_string, "../local/map_dag_modelstring_theorybased.rds")


```

