---
title: "int-theory-vacc PCA analysis"
output: html_notebook
---

During my visit to UCSD, several faculty I met with suggested taking a "dimensionality reduction" approach to examining these data. Ed Vul in particular suggested there may only be 1 or 2 components underlying these data, and that we could use changes in those components to predict the changes in the scales. He suggested I could "project" the changes in disease severity onto principle component space, and use that to simulate changes across beliefs following evidence.

This notebook is an attempt to test these suggestions.

```{r}
# library(FactoMineR)
library(tidyverse)
library(ggrepel)

source("../scripts/load-data-s1.R", chdir = TRUE)
source("../scripts/load-data-s2.R", chdir = TRUE)

# rescale_beta <- function(x, lower, upper) {
#   # rescales onto the open interval (0,1)
#   # rescales over theoretical bounds of measurement, specified by "upper" and "lower"
# 
#   N <- length(x)
#   res <- (x - lower) / (upper - lower)
#   res <- (res * (N - 1) + .5) / N
# 
#   return(as.vector(res))
# }

# d_bn_scaled <- d_bn %>%
#  mutate_all(scale)

## set the seed to make your partition reproductible
set.seed(123)
trainInd <- sample(seq_len(nrow(d_bn)), size = floor(nrow(d_bn)*.80))

train <- d_bn[trainInd, ]
test <- d_bn[-trainInd, ]
```

## Exploring components

Let's look at how many factors we need to capture these data ...

```{r}
pca14 <- prcomp(train, scale. = TRUE, rank=14)

summary(pca14)
```

Fist factor gives 44% the variance. First 3 factors give 66% of the variance. That would be of similar complexity to the full Bayesian network model, in terms of number of parameters (33 edges + 14 leak nodes vs 14*3 loadings). From there, looks like you can get 85% of variance with 8 factors, 95% with 11 factors, and need 13 to get 99%.

## quick plots

To try to get a sense of these components, I'll look at the space of loadings for the first few factors.

```{r}

loadings <-  as.data.frame(pca14$rotation)

loadings %>%
  ggplot(aes(x=PC1, y = PC2, label=rownames(loadings))) +
  geom_point(color="red") +
  geom_text_repel() +
  theme_bw() +
  labs(title="Component Loadings")

loadings %>%
  ggplot(aes(x=PC1, y = PC3, label=rownames(loadings))) +
  geom_point(color="red") +
  geom_text_repel() +
  theme_bw() +
  labs(title="Component Loadings")

loadings %>%
  ggplot(aes(x=PC2, y = PC3, label=rownames(loadings))) +
  geom_point(color="red") +
  geom_text_repel() +
  theme_bw() +
  labs(title="Component Loadings")
```

Looks like PC1 is roughly, do you want to vaccinate or not. PC2 is less interpretable, but it seems to be separating out some of the oddballs, like infant immune system beliefs, and some kind of polarity b/c disease rare is on the opposite extreme. PC3 is kind of similar, I can't get much of a sense for it.

Now, to validate, let's see how a 3-component PCA solution reconstructs the test data.

```{r pca functions}
pca_reconstruct <- function(pca, newdata=NULL){
  # reconstruct data from pca compression
  # newdata: new data to reconstruct (in pca dimension)
  if (is_null(newdata)){
    newdata <- pca$x
  }
  
  if (dim(newdata)[1]==1) {
    newdata <- t(newdata) # pca with rank 1 behaves strangely for some reason
  }
  
  z <-  t(pca$rotation %*% t(newdata))
  z <- t(apply(z, 1, function(x){x*pca$scale + pca$center}))
  
  return(z)
}

pca_map_changes <- function(x, varname, pca, df=NULL) {
  # x: change in original units
  # varname: variable name as string
  # pca: pca solution (from prcomp)
  # returns new pc scores after change
  
  if (is_null(df)){
    df <- pca$x
  }
  
  if (is.numeric(pca$scale)) {
    scaled_change <- x/pca$scale[varname]
  } else {
    scaled_change <- x
  }

  var_loading <- pca$rotation[varname,]
  t(apply(df, 1, function(x){x + scaled_change*var_loading}))
}
```

```{r}
pca3 <- prcomp(train, scale. = TRUE, rank=3)
test_predicted <- pca_reconstruct(pca3, newdata = predict(pca3,test))

df_preds <- test_predicted %>%
  as_tibble() %>%
  mutate(id = seq(1,nrow(test))) %>%
  gather(scale, response, -id) %>%
  mutate(type = "predicted") %>%
  bind_rows(
    (
      test %>%
        mutate(id = seq(1,nrow(test))) %>%
        gather(scale, response, -id) %>%
        mutate(type = "observed")
    )
  ) %>%
  spread(type,response)

cors <- df_preds %>%
  group_by(scale) %>%
  summarize(correlation = cor(predicted, observed))

df_preds %>%
  ggplot(aes(x=predicted, y = observed)) +
  geom_point(shape=1, size=.5, color="darkturquoise") +
  geom_text(data = cors, inherit.aes = FALSE, aes(x = 3, y = -2, label=round(correlation,2))) +
  facet_wrap(~scale, nrow=2) +
  theme_bw() +
  theme(aspect.ratio=1)
``` 

Pretty good, as we would expect based on the variance accounted for. Three factors get approximately 65% of the variance, but the quality of predictions are a bit more even across scales (e.g., r = .66 for overparenting, vs .3 or so for bn). That's not necessarily surprising given the purpose of PCA. Overall however, predictions are of comaprable quality compared to the bayesian network model. Using fewer principle components does worse, so there isn't an opportunity for an appreciably "simpler" solution in number of parameters, or in degree of data reduction.

## Predicting changes using PCA

So now I'll take the PCA solution and try to generate predictions for how beliefs will change given a change in disease severity beliefs. 

First, need to prepare data on observed changes for each scale.

```{r}

d_interv_pre <- d_scored %>%
  filter(condition=="diseaseRisk", phase=="pre") %>%
  spread(scale,mean) %>%
  select(-workerId, -condition, -phase)
  
d_changes <- d_scored %>%
  filter(condition=="diseaseRisk") %>%
  spread(phase, mean) %>%
  mutate(change = post-pre) %>%
  select(-pre,-post) %>%
  group_by(scale) %>%
  summarize(meanChange = mean(change))

d_changes
```


Then, need to map changes in disease severity beliefs onto pca space. Then, can generate predictions with reconstruction, projecting back into the original 14d space.

```{r}

pca3 <- prcomp(train, scale. = TRUE, rank=1)

# put s2 data in pca space
pre_pca <- predict(pca3, d_interv_pre)

# # map changes in diseaseSevere onto pca space
pre_pca_mod <- pca_map_changes(.32, "diseaseSevere", pca3, df=pre_pca) # based on observed change
# pre_pca_mod <- pca_map_changes(1.1, "diseaseSevere", pca3, df=pre_pca) # to approx obs change in pred vals

# # predict posttest scores by reconstruction from new pca values
pred_post<- pca_reconstruct(pca3, newdata = pre_pca_mod)

pred_post %>%
  as_tibble() %>%
  gather(scale, response) %>%
  group_by(scale) %>%
  summarize(posttest = mean(response)) %>%
  left_join(
    (
      d_interv_pre %>%
  gather(scale,response) %>%
  group_by(scale) %>%
  summarize(pretest = mean(response))
    ), by = "scale"
  ) %>%
  mutate(change = posttest-pretest) -> pred_changes

d_changes %>%
  rename(obs_changes = meanChange) %>%
  left_join(pred_changes) -> pred_obs_changes

cor(pred_obs_changes$obs_changes, pred_obs_changes$change)

pred_obs_changes %>%
  ggplot(aes(x=change, y=obs_changes)) +
  geom_point() +
  geom_abline(intercept=0, slope=1, linetype="dashed", alpha=.5) +
  theme_bw() +
  xlim(-.5,1) +
  ylim(-.5,1) +
  theme(aspect.ratio=1)
```

Seems to do quite poorly! Would be good to get another set of eyes on it, but I'm pretty confident my code is working. At least, when I use a full factor solution it adds the correct amount to disease severity scores and only disease severity scores. I'm not 100% sure this is exactly what Ed Vul and others have meant by using PCA, but it seems like the analogous approach.

So, tentatively, I don't think this PCA idea gives a very good solution and certainly it's hard to see it as an improvement (except maybe in ease of use and computation speed). It takes a similar number of parameters to get a similarly good reconstruction of S1 data, and the pca technique fails to predict changes in beliefs following evidence in S2.

