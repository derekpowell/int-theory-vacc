---
title: "int-theory-vacc: Study 2 modeling"
output: 
  html_notebook: 
    code_folding: hide
    # toc: true
    # toc_float: true
---



```{r load in existing objects, message=FALSE, warning=FALSE}
# net.struct <- readRDS("net-struct-cogsci2018.rds")

source("../study1/vacc_import_data.R", chdir = TRUE)
source("../scripts/gmod_tools.R")
# source("../../Scripts/virtualEvidence.R")

library(bnlearn)
library(rjags)
library(patchwork)
library(BiDAG)
library(HydeNet)
library(bnlearn)

library(rsample)

source("../scripts/custom-structure-learning/cog-model-main.R", chdir = TRUE)
```

```{r set up training split}
# rescale beta

rescale_beta <- function(x, lower, upper) {
  # rescales onto the open interval (0,1)
  # rescales over theoretical bounds of measurement, specified by "upper" and "lower"

  N <- length(x)
  res <- (x - lower) / (upper - lower)
  res <- (res * (N - 1) + .5) / N

  return(as.vector(res))
}

d_bn_scaled <- d_bn %>%
 mutate_all(function(x){rescale_beta(x,-3,3)})

## set the seed to make your partition reproductible
set.seed(123)
trainInd <- sample(seq_len(nrow(d_bn_scaled)), size = floor(nrow(d_bn_scaled)*.80))

train <- d_bn_scaled[trainInd, ]
test <- d_bn_scaled[-trainInd, ]
```


# loading in data model


```{r}
# first load in mcmc results
all_results <- readRDS("../local/allresults.rds")
nodes <- colnames(train)
# then grab map dag for theory-based constraints
merged_chains <- merge_chains(all_results[[5]])
map_dag <- extract_mapdag(merged_chains)

h <- HydeNetwork(as.formula(bnlearn_to_hyde_string(map_dag)))
plot(h)
```

## Translate into cognitive model

```{r}
# parse bn into list of parents and children

arcs_df <- bnlearn_to_df(map_dag)

df_to_list <- function(arcs_df, as.strings=FALSE) {
  # take arcs_df and make list of formulas
  arcs_df$to <- as.character(arcs_df$to)
  arcs_df$from <- as.character(arcs_df$from)

  nodes <- unique(unlist(arcs_df))
  output <- lapply(nodes, function(node) {
    edges <- arcs_df[which(arcs_df$to == node), "from"]
    if (length(edges) < 1) {
      edges <- NULL
    }
    list(child=node, parents=edges)
 
  })
  names(output) <- nodes
  return(output)
}

graph_list <- df_to_list(arcs_df)

bagOfModels <- lapply(graph_list, function(x){fit_node_cpt(x, train)})

# bagNet <- HydeNetwork(bagOfModels)
# writeNetworkModel(bagNet, pretty=TRUE)

```

Compute and add evidence cpt

```{r}
inv_logit <- plogis
logit <- qlogis

evid_score_func <- function(data, par) {
  
  inv_logit <- plogis
  logit <- qlogis

  pred_y <- with(data,
                 {
                   inv_logit(logit(pre) + evid*par[2] + par[1])
                 }
       )
  pred_beta_A <- pred_y * par[3]
  pred_beta_B <- (1-pred_y) * par[3]
  
  ll <- -1 * sum(dbeta(data$post, pred_beta_A, pred_beta_B, log=TRUE)) # beta regression
  return(ll)
}

get_evid_probs <- function(result){
  # this is a heuristic/hack, could be made better but probably doesn't matter
  evid_ratio <- exp(result$par[1] + result$par[2])
  if (evid_ratio < 1) {
    p0 <- .90
  } else {
    p0 <- .50
  }
  
  if (p0*evid_ratio > 1) {
    p0 <- p0*.9/(p0*evid_ratio)
  }

  p1 <- p0*evid_ratio
  
  c(p0,p1)
}


evid_probs_to_cpt <- function(probs, var_name){
  p0 <- probs[1]
  p1 <- probs[2]
  
  full_list <- paste0("list(",var_name,"=c('Yes','No'), evid = c('Yes', 'No'))")
  make_custom_cpt(c(p1, p0, (1-p1), (1-p0)), c(2,2), eval(parse(text=full_list)), NULL)
}


find_evid_ratio <- function(data){
  optim(par = c(0, 0, 5), fn = evid_score_func, data = data, method="BFGS")
}


make_evid_cpt <- function(data, var_name){
  result <- find_evid_ratio(data)
  probs <- get_evid_probs(result)
  cpt <- evid_probs_to_cpt(probs, var_name)
  
  return(cpt)
}


```

```{r}
source("../study2/load-study2-data.R", chdir = TRUE)

d <- d_scored %>%
  filter(scale == "diseaseSevere") %>%
  mutate(mean = rescale_beta(mean, -3, 3)) %>%
  spread(phase, mean) %>% 
  mutate(condition = relevel(condition, ref="noInterv")) %>%
  mutate(evid = ifelse(condition=="noInterv",0,1))

evid_cpt <- make_evid_cpt(d, "diseaseSevere")

bagOfModels$evid <- evid_cpt

bagNet <- HydeNetwork(bagOfModels)
plot(bagNet)
writeNetworkModel(bagNet, pretty=TRUE)
## In the future (soon), make a function to create this node cpt

```

Generate predictions ...

__Translating hydenet model to bnlearn__

below is some code to get things into the right format. Later I'll break this out into a function I guess.

```{r}
hyde_to_bn_cpt <- function(hyde_cpt) {
  ndims <- length(dim(hyde_cpt))
  
  if ("xtabs" %in% class(hyde_cpt)) {
    output <- hyde_cpt/1e5
  } else {
    
    output <- aperm(hyde_cpt, ndims:1)
  }
 return (output) 
}

# hyde_to_bn_cpt(bagOfModels$evid)

bnlearn_models <- lapply(bagOfModels, hyde_to_bn_cpt)

model_string <- as.character(map_dag)
model_string <- paste0(model_string,"[evid|diseaseSevere]")
model_network <- model2network(model_string)

predModel <- custom.fit(model_network, dist = bnlearn_models)


```

__Generating predictions__

Now I can use this model to generate predictions.

```{r}
set.seed(12345)

pred0 <- sapply(nodes, function(x){
  statement <- paste0("cpquery(predModel, event = (", x, " == 'Yes'), evidence=TRUE, n = 5e5)")
  eval(parse(text=statement))
})

pred1 <- sapply(nodes, function(x){
  statement <- paste0("cpquery(predModel, event = (", x, " == 'Yes'), evidence= (evid == 'Yes'), n = 5e5)")
  eval(parse(text=statement))
})

pred_changes <- pred1 - pred0

pred_changes <- as.data.frame(pred_changes)

pred_changes <- pred_changes %>%
  mutate(scale = nodes) %>%
  rename(Mean = pred_changes) %>%
  mutate(type = "predicted")

```

Compare predicted and observed changes ...

```{r}


obs_changes <- d_scored %>%
  mutate(mean = rescale_beta(mean, -3, 3)) %>%
  spread(phase,mean) %>%
  mutate(changeScore = post-pre) %>%
  filter(condition == "diseaseRisk") %>%
  group_by(scale) %>%
  summarise(
    Mean = mean(changeScore),
    ul = mean(changeScore) + 1.96*sd(changeScore)/sqrt(n()), # replace with bootstrapping
    ll = mean(changeScore) - 1.96*sd(changeScore)/sqrt(n())
    ) %>%
  mutate(type = "observed")

obs_pred <- bind_rows(pred_changes, obs_changes) %>%
  spread(type, Mean) %>%
  group_by(scale) %>%
  summarize_all(mean, na.rm=TRUE)

cor(obs_pred$predicted, obs_pred$observed)

obs_pred %>% # a bit of a hack
  ggplot(aes(x=predicted, y = observed, ymin = ll, ymax=ul)) +
  geom_abline(slope=1, intercept=0, linetype="dashed", alpha =.5) +
  geom_point() +
  geom_errorbar() +
  coord_cartesian(xlim=c(-.06,.08), ylim=c(-.06,.08)) +
  theme_bw() +
  theme(aspect.ratio = 1)

obs_pred %>%
  gather(type, Mean, observed, predicted) %>%
  ggplot(aes(y = reorder(scale, Mean), x = Mean, xmin = ll, xmax = ul, color=type)) +
  geom_point() +
  geom_errorbarh(height=0)
```



# What beliefs are targetted by the intervention?

Here we can pretend that expectations for the intervention materials are set by each of the 14 beliefs, and compare the accuracy of the resulting models' predictions. We should also ask whether the differences among models are substantial and reliable enough for us to prefer any one model over another.

```{r}
create_bnlearn_cog_model <- function(dag, data, evid_cpt = NULL, targetted_belief = NULL) {
  arcs_df <- bnlearn_to_df(dag)
  graph_list <- df_to_list(arcs_df)
  bagOfModels <- lapply(graph_list, function(x){fit_node_cpt(x, data)})
  model_string <- as.character(dag)

  if (!(is.null(evid_cpt))) {
    bagOfModels$evid <- evid_cpt
    model_string <- paste0(model_string,"[evid|", targetted_belief, "]")
  }
  model_network <- model2network(model_string)
  bnlearn_models <- lapply(bagOfModels, hyde_to_bn_cpt)
  predModel <- custom.fit(model_network, dist = bnlearn_models)

  return(predModel)
}


add_evid_node <- function(data, bnlearn_model, targetted_belief) {
  
  evid_cpt <- make_evid_cpt(data, targetted_belief)
  model_list <- lapply(bnlearn_model, function(x){x$prob})
  model_list$evid <- hyde_to_bn_cpt(evid_cpt)
  
  model_string <- modelstring(bnlearn_model)
  model_string <- paste0(model_string,"[evid|", targetted_belief, "]")
  model_network <- model2network(model_string)
  predModel <- custom.fit(model_network, dist = model_list)
  
  return(predModel)
}


```


```{r}
filter_dscored <- function(data, scale_name){
  
  data %>%
  filter(scale == scale_name) %>%
  mutate(mean = rescale_beta(mean, -3, 3)) %>%
  spread(phase, mean) %>% 
  mutate(condition = relevel(condition, ref="noInterv")) %>%
  mutate(evid = ifelse(condition=="noInterv",0,1))
}

cogModel_predictions <- function(model){
  pred0 <- sapply(nodes, function(x){
  statement <- paste0("cpquery(model, event = (", x, " == 'Yes'), evidence=TRUE, n = 1e5)")
  eval(parse(text=statement))
  })
  
  pred1 <- sapply(nodes, function(x){
    statement <- paste0("cpquery(model, event = (", x, " == 'Yes'), evidence= (evid == 'Yes'), n = 1e5)")
    eval(parse(text=statement))
  })
  
  pred_changes <- pred1 - pred0
  
  pred_changes <- as.data.frame(pred_changes)
  
  pred_changes <- pred_changes %>%
    mutate(scale = nodes) %>%
    rename(Mean = pred_changes) %>%
    mutate(type = "predicted")
  
  return(pred_changes)
}


compare_pred_obs_r <- function(predicted, observed){

  obs_pred <- suppressWarnings(bind_rows(predicted, observed)) %>%
    spread(type, Mean) %>%
    group_by(scale) %>%
    summarize_all(mean, na.rm=TRUE)
  
  cor(obs_pred$predicted, obs_pred$observed)
}

compare_pred_obs_rmse <- function(predicted, observed){

  obs_pred <- suppressWarnings(bind_rows(predicted, observed)) %>%
    spread(type, Mean) %>%
    group_by(scale) %>%
    summarize_all(mean, na.rm=TRUE)
  
  sqrt(mean((obs_pred$observed-obs_pred$predicted)^2))
  
}


extract_obs_changes <- function(observed){
  obs_changes <- observed %>%
  mutate(mean = rescale_beta(mean, -3, 3)) %>%
  spread(phase,mean) %>%
  mutate(changeScore = post-pre) %>%
  filter(condition == "diseaseRisk") %>%
  group_by(scale) %>%
  summarise(
    Mean = mean(changeScore),
    ul = mean(changeScore) + 1.96*sd(changeScore)/sqrt(n()), # replace with bootstrapping
    ll = mean(changeScore) - 1.96*sd(changeScore)/sqrt(n())
    ) %>%
  mutate(type = "observed")
}

```

```{r}
# -- takes about 20 min
base_model <- create_bnlearn_cog_model(map_dag, train)

# do bootstrap comparison
set.seed(1234)
t1 <- Sys.time()

boot_fits <- as_tibble(expand.grid(
  list(
    replicate = 1:100, scale = nodes
  )
)) %>%
  nest(-replicate, .key="scales") %>%
  mutate(boot_d_scored = map(replicate, function(x) {
    totaln <- length(unique(d_scored$workerId))
    d_scored %>%
      nest(-workerId) %>%
      sample_n(totaln, replace = TRUE) %>%
      mutate(uniqueId = 1:totaln) %>%
      unnest()
  })) %>%
  unnest(scales, .drop=FALSE) %>%
  mutate(
      boot_d = map2(boot_d_scored, scale, function(x,y){filter_dscored(x, y)}),
      obs_changes = map(boot_d_scored, extract_obs_changes)
      ) %>%
  select(-boot_d_scored) %>%
  mutate(
    models = map2(boot_d, scale, function(x,y){add_evid_node(x, base_model, y)}),
    pred_changes = map(models, cogModel_predictions),
    r = map2_dbl(pred_changes, obs_changes, compare_pred_obs_r),
    rmse = map2_dbl(pred_changes, obs_changes, compare_pred_obs_rmse)
    )

print(Sys.time() - t1)
```

```{r}
boot_fits %>%
  mutate(r2 = r^2) %>%
  ggplot(aes(x=reorder(scale,-r2), y = r2)) +
  geom_boxplot(fill="lightgray") +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

boot_fits %>%
  ggplot(aes(x=reorder(scale,-r), y = rmse)) +
  # geom_violin(fill="gray", alpha=.5) +
  geom_boxplot(fill = "lightgray") +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


```{r}
boot_fits %>% 
  filter(scale=="diseaseSevere") %>%
  summarize(
    estimate = mean(r),
    ul = quantile(r,.975),
    ll = quantile(r, .025)
    )
```

