---
title: 'Vaccines: Many Beliefs Study 3: Analysis'
author: "Derek Powell, Kara Weisman"
date: "2018-05-01"
output: html_notebook
---

```{r, include = F}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

```{r setup, include = F}
library(tidyverse)
library(psych)
# library(ggcorrplot)
library(lme4)
library(brms)
library(rms)
```

# Data prep

```{r}
source("./load-study2-data.R")
```

```{r tidy, include = F}
# how many left?
d %>% distinct(workerId, condition) %>% count(condition)
```


# Score distributions

First, let's look at the distributions of scores for all scales, pre- and post-test:

```{r scores histo, fig.width = 7, fig.height = 2}
ggplot(d_scored, 
       aes(x = mean, fill = phase)) +
  # facet_wrap(~ scale, ncol = 5) +
  facet_grid(condition ~ scale) +
  geom_histogram(bins = 14, position = "identity", alpha = 0.6) +
  scale_x_continuous(breaks = seq(-3, 3, 1)) + 
  theme_bw() +
  labs(title = "distributions of scores by scale, condition, and phase (pre/post)")
```

```{r scores density plot, fig.width = 7, fig.height = 2, include = F}
# ggplot(d_scored, 
#        aes(x = mean, fill = phase, color = phase)) +
#   # facet_wrap(~ scale, ncol = 5) +
#   facet_grid(condition ~ scale) +
#   geom_density(alpha = 0.5) +
#   scale_x_continuous(breaks = seq(-3, 3, 1)) + 
#   theme_bw() +
#   labs(title = "distributions of scores by scale, condition, and phase (pre/post)")
```

It looks like there's a lot of overlap in the pre- and post-test distrubtions for all scales - though a few hints of subtle shifts (e.g., in `diseaseRare`, `vaccIntent`).

# Visual comparison of pre- vs. post-intervention

Let's compare participants' responses pre- vs. post-intervention on all scales. I'll plot both mean pre- and post-intervention scores, as well as mean difference scores (note separate axes):

```{r plot means, fig.width = 3, fig.asp = 3}
d_means <- d_scored %>%
  distinct(workerId, condition, phase, scale, mean) %>%
  group_by(condition, phase, scale) %>%
  # summarise(Mean = mean(mean, na.rm = T),
  #           Lower = Mean - 2 * sd(mean, na.rm = T)/sqrt(n()),
  #           Upper = Mean + 2 * sd(mean, na.rm = T)/sqrt(n())) %>%
  do(data.frame(rbind(smean.cl.boot(.$mean)))) %>% # bootstrapped 95% CI
  ungroup() %>%
  distinct() %>%
  mutate(scale = factor(scale,
                        levels = c("vaccIntent", "vaccDanger", "vaccEff", 
                                   "vaccStrain", "vaccTox", 
                                   "diseaseSevere", "diseaseRare", 
                                   "infantImmLimCap", "infantImmWeak", 
                                   "medSkept", "hb", "nat", 
                                   "overpar", "parentExpert")),
         condition = factor(condition,
                            levels = c("diseaseRisk", "autismCorr", "noInterv")))

g_means <- ggplot(d_means,
                  aes(x = phase, y = Mean,
                      color = condition, group = condition)) +
  facet_wrap(~ scale, ncol = 3) +
  geom_path(position = position_dodge(width = 0.1)) +
  geom_linerange(aes(ymin = Lower, ymax = Upper),
                 position = position_dodge(width = 0.1)) +
  geom_point(size = 3,
             position = position_dodge(width = 0.1)) +
  scale_y_continuous("mean score", 
                     # limits = c(-3, 3),
                     breaks = seq(-3, 3, 1)) +
  scale_color_brewer(palette = "Set1", direction = -1) +
  theme_bw() +
  theme(legend.position = "bottom") +
  labs(title = "mean scores by phase and condition",
       subtitle = "error bars are bootstrapped 95% CIs")

g_means
```

```{r plot diffs}
d_diffs <- d_scored %>%
  spread(phase, mean) %>%
  mutate(post_pre_diff = post - pre) %>%
  group_by(condition, scale) %>%
  do(data.frame(rbind(smean.cl.boot(.$post_pre_diff)))) %>%
  ungroup() %>%
  mutate(scale = factor(scale,
                        levels = c("vaccIntent", "vaccDanger", "vaccEff", 
                                   "vaccStrain", "vaccTox", 
                                   "diseaseSevere", "diseaseRare", 
                                   "infantImmLimCap", "infantImmWeak", 
                                   "medSkept", "hb", "nat", 
                                   "overpar", "parentExpert")),
         condition = factor(condition,
                            levels = c("diseaseRisk", "autismCorr", "noInterv")))

g_diffs <- ggplot(d_diffs,
                  aes(x = scale, y = Mean, 
                      color = condition, group = condition)) +
  # facet_wrap(~ scale, ncol = 3) +
  geom_hline(yintercept = 0, lty = 2, size = 0.5) +
  geom_linerange(aes(ymin = Lower, ymax = Upper)) +
  geom_point(size = 3) +
  scale_y_continuous("mean diff") + #, 
                     # limits = c(-3, 3), 
                     # breaks = seq(-3, 3, 1)) +
  scale_color_brewer(palette = "Set1", direction = -1) +
  theme_bw() +
  theme(
    # legend.position = "none",
        axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "mean difference scores by scale and condition",
       subtitle = "error bars are 95% bootstrapped CIs")

g_diffs
```

```{r plot means and diffs, fig.width = 3, fig.asp = 3}
multiplicand <- 6
multi_fun <- function(x, multi = multiplicand){return(x * multi)}
g_means +
  geom_segment(aes(x = 2.5, xend = 3.5, y = 0, yend = 0), 
               color = "black", lty = "dashed", size = 0.3) +
  geom_linerange(data = d_diffs %>% 
                   mutate_at(vars(Mean, Lower, Upper), funs(multi_fun)) %>%
                   mutate(phase = "diff"),
                 aes(x = phase, ymin = Lower, ymax = Upper),
                 position = position_dodge(width = 0.5)) +
  geom_point(data = d_diffs %>%
               mutate_at(vars(Mean, Lower, Upper), funs(multi_fun)) %>%
               mutate(phase = "diff"),
             aes(x = phase, y = Mean),
             position = position_dodge(width = 0.5),
             size = 2, shape = 17) +
  scale_x_discrete(limits = c("pre", "post", "diff")) +
  scale_y_continuous("mean score", breaks = seq(-3, 3, 1),
                     sec.axis = sec_axis(~./multiplicand, 
                                         name = "mean diff")) +
  scale_color_brewer(palette = "Set1", direction = -1) +
  theme(legend.position = "top", 
        panel.grid.minor.y = element_blank()) +
  labs(title = "means and mean difference scores by scale and condition",
       subtitle = "error bars are 95% bootstrapped CIs\nNOTE:use left y-axis for pre and post phases, right y-axis for difference scores")
```

Some interesting things might be going on here! Probably most useful paired with some actual stats...

# Regression analyses

First, let's choose how to code our data - I've set up contrast coding, effect coding and dummy coding options here, and I'll go with dummy-coding for now (with `noInterv` and `pre` as the baselines for comparison for condition and phase, respectively).

```{r contrasts, include = F}
# # orthogonal contrast coding
# contrasts(d_scored$condition) <- cbind(interv_none = c(1, 1, -2),
#                                        DR_AC = c(1, -1, 0))
# contrasts(d_scored$phase) <- cbind(post_GM = c(-1, 1))

# # effect coding
# contrasts(d_scored$condition) <- cbind(DR_GM = c(1, 0, -1),
#                                        AC_GM = c(0, 1, -1))
# contrasts(d_scored$phase) <- cbind(post_GM = c(-1, 1))

# dummy coding
contrasts(d_scored$condition) <- cbind(DR_none = c(0, 1))
contrasts(d_scored$phase) <- cbind(post_pre = c(0, 1))
```

```{r print contrasts}
# print out contrasts
contrasts(d_scored$condition)
contrasts(d_scored$phase)
```

## By scale

This is rather crazy (and of course exploratory) endeavor, and very vulnerable to multiple comparisons... but let's look at the effects on all scales individually.

### Beliefs about vaccines

#### Intentions to vaccinate (`vaccIntent`)

<span style="color:blue">**NOTE**: This is our main DV of interest.</span>

```{r regression vaccIntent}
# vaccIntent
r1_vaccIntent <- lmer(mean ~ phase * condition + (1 | workerId),
                      data = d_scored %>% filter(scale == "vaccIntent"))
summary(r1_vaccIntent)
```

Success! In the form of a significant interaction between phase and condition  (`phasepost_pre:conditionDR_none`: change from pre- to post-intervention in the Disease Risk vs. No Intervention conditions).

An analysis with change scores (a la Horne, Powell, et al. (2015, *PNAS*)):

```{r regression change scores vaccIntent}
# vaccIntent
r2_vaccIntent <- lm(diff ~ condition,
                    data = d_scored %>% 
                      filter(scale == "vaccIntent") %>%
                      spread(phase, mean) %>%
                      mutate(diff = post - pre))
summary(r2_vaccIntent)

# # in case you want to check equivalence to ANOVA
# r3_vaccIntent <- oneway.test(diff ~ condition,
#                              data = d_scored %>%
#                                filter(scale == "vaccIntent") %>%
#                                spread(phase, mean) %>%
#                                mutate(diff = post - pre),
#                              var.equal = TRUE)
# r3_vaccIntent
```

Again, success!

Here's the relevant plot from the *PNAS* paper:

```{r plot change scores vaccIntent, fig.width = 2, fig.height = 2}
ggplot(d_diffs %>% filter(scale == "vaccIntent"),
       aes(x = condition, y = Mean, fill = condition)) +
  geom_hline(yintercept = 0, lty = 2) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.1) +
  scale_y_continuous("vaccIntent change score", limits = c(-.25, .5)) +
  scale_fill_brewer(palette = "Set1", direction = -1) +
  theme_bw() +
  theme(legend.position = "none") +
  labs(subtitle = "error bars are 95% bootstrapped CIs")
```

#### Vaccine danger (`vaccDanger`)

```{r regression vaccDanger}
# vaccDanger
r1_vaccDanger <- lmer(mean ~ phase * condition + (1 | workerId),
                      data = d_scored %>% filter(scale == "vaccDanger"))
summary(r1_vaccDanger)
```

#### Vaccine efficacy (`vaccEff`)

```{r regression vaccEff}
# vaccEff
r1_vaccEff <- lmer(mean ~ phase * condition + (1 | workerId),
                   data = d_scored %>% filter(scale == "vaccEff"))
summary(r1_vaccEff)
```

#### Vaccines' tendency to strain the infant immune system (`vaccStrain`)

```{r regression vaccStrain}
# vaccStrain
r1_vaccStrain <- lmer(mean ~ phase * condition + (1 | workerId),
                      data = d_scored %>% filter(scale == "vaccStrain"))
summary(r1_vaccStrain)
```

#### Vaccine toxicity (`vaccTox`)

```{r regression vaccTox}
# vaccTox
r1_vaccTox <- lmer(mean ~ phase * condition + (1 | workerId),
                   data = d_scored %>% filter(scale == "vaccTox"))
summary(r1_vaccTox)
```

### Beliefs about diseases

#### Disease severity (`diseaseSevere`)

<span style="color:blue">**NOTE**: This is the scale that we thought the Disease Risk intervention should affect most directly.</span>

```{r regression diseaseSevere}
# diseaseSevere
r1_diseaseSevere <- lmer(mean ~ phase * condition + (1 | workerId),
                         data = d_scored %>% filter(scale == "diseaseSevere"))
summary(r1_diseaseSevere)
```

#### Disease rarity (`diseaseRare`)

```{r regression diseaseRare}
# diseaseRare
r1_diseaseRare <- lmer(mean ~ phase * condition + (1 | workerId),
                       data = d_scored %>% filter(scale == "diseaseRare"))
summary(r1_diseaseRare)
```

### Beliefs about infants' immune systems

#### Limited capacity of infants' immune systems (`infantImmLimCap`)

```{r regression infantImmLimCap}
# infantImmLimCap
r1_infantImmLimCap <- lmer(mean ~ phase * condition + (1 | workerId),
                           data = d_scored %>% filter(scale == "infantImmLimCap"))
summary(r1_infantImmLimCap)
```

#### Weakness of infants' immune systems (`infantImmWeak`)

```{r regression infantImmWeak}
# infantImmWeak
r1_infantImmWeak <- lmer(mean ~ phase * condition + (1 | workerId),
                         data = d_scored %>% filter(scale == "infantImmWeak"))
summary(r1_infantImmWeak)
```

### Other beliefs, attitudes, and worldviews

#### Medical skepticism (`medSkept`)

```{r regression medSkept}
# medSkept
r1_medSkept <- lmer(mean ~ phase * condition + (1 | workerId),
                    data = d_scored %>% filter(scale == "medSkept"))
summary(r1_medSkept)
```

#### Holistic balance (`hb`)

```{r regression hb}
# hb
r1_hb <- lmer(mean ~ phase * condition + (1 | workerId),
              data = d_scored %>% filter(scale == "hb"))
summary(r1_hb)
```

#### Naturalism (`nat`)

```{r regression nat}
# nat
r1_nat <- lmer(mean ~ phase * condition + (1 | workerId),
               data = d_scored %>% filter(scale == "nat"))
summary(r1_nat)
```

#### Overparenting (`overpar`)

```{r regression overpar}
# overpar
r1_overpar <- lmer(mean ~ phase * condition + (1 | workerId),
                   data = d_scored %>% filter(scale == "overpar"))
summary(r1_overpar)
```

#### Parental Expertise (`parentExpert`)

```{r regression parentExpert}
# parentExpert
r1_parentExpert <- lmer(mean ~ phase * condition + (1 | workerId),
                        data = d_scored %>% filter(scale == "parentExpert"))
summary(r1_parentExpert)
```

# Other stuff

## Violin plots

With violin plots, we can see the full distribution of scores at each time point in each condition:

```{r plot violin, fig.width = 3, fig.height = 5}
ggplot(d_scored,
       aes(x = interaction(phase, condition), y = mean, # fill = condition, 
           group = interaction(phase, condition))) +
  facet_wrap(~ scale, ncol = 3) +
  geom_point(aes(color = condition),
             position = position_jitter(width = 0.3, height = 0), 
             alpha = 0.5) +
  # geom_boxplot(alpha = 0) +
  geom_violin(alpha = 0,
              draw_quantiles = c(0.25, 0.5, 0.75)) +
  scale_y_continuous("mean score", 
                     limits = c(-3, 3), 
                     breaks = seq(-3, 3, 1)) +
  scale_x_discrete("phase by condition",
                   labels = rep(c("pre", "post"), 3)) +
  theme_bw() +
  theme(legend.position = "bottom") + #,
        # axis.text.x = element_text(angle = 90, hjust = 1))
  labs(title = "violin plot of pre- and post-intervention scores by scale and condition",
       subtitle = "horizontal lines correspond to 25th, 50th, and 75th percentiles")
```

# Derek's analyses

_DATE_: March 13, 2018 3:52 PM

I'm going to pick up here and do some further regression analyses. I'll look at this data in the way I *wish* we'd looked at the original PNAS data.

That is, (1) using an ordinal HLM regression over the five separate scale items (conceptually, I think, similar to SEM-style approaches), and (2) using beta regression.

There are two general model forms that I think are reasonable for looking at this. First:

```
response ~ phase * condition
```

Kara already tried this general approach, saving the model as `r1_vaccIntent`. So the only difference here will be the distributions I use. In this case, the interaction term is required, and the real thing to test is the phase*condition interaction. 

And second:

```
post_response ~ pre_response * condition
```

Here pre_response could be the response on the overall pre-test scale, or the individual items. In addition, the interaction terms are optional, as warranted by the data. I'd wager this is the more familiar approach for most psychologists.

## Ordinal HLM

### Predicting "response"

```{r}
devtools::source_gist(id = "f1994c0f8325abbc5d300600744af39d", filename="cbrm.R")

library(brms)
# fit_ord <- cbrm(response ~ condition * phase + (1|workerId) + (1|question),
#                data = d %>%
#                     filter(scale=="vaccIntent") %>%
#                     mutate(
#                       condition = relevel(condition, ref="noInterv"),
#                       response = response + 4),
#                family=cumulative(),
#                control = list(adapt_delta = .85),
#                cores = parallel::detectCores(),
#                iter = 2000)
#                # cached_file = "fit_ord.rds")
# summary(fit_ord)
```

### Predicting post-test

Here `pre` is the specific item pre-test score and `preMean` is the mean of the scale at pretest.

```{r}
d1 <- d %>%
  filter(scale=="vaccIntent") %>%
  mutate(condition = relevel(condition, ref="noInterv")) %>%
  spread(phase,response) %>%
  select(pre, post, condition, workerId, question) %>%
  {
    {. -> tmp} %>%
      group_by(workerId) %>%
      summarise(preMean = mean(pre)) %>%
      mutate(preMean = scale(preMean)) %>%
      left_join(tmp, by = "workerId")
  } %>%
  mutate(post = post + 4)
```


```{r}
# fit_ord2 <- cbrm(post ~ condition + preMean + (1|workerId) + (1|question),
#                data=d1,
#                family=cumulative(),
#                control = list(adapt_delta = .85),
#                cores = parallel::detectCores(),
#                iter = 2000)
#                # cached_file = "fit_ord2.rds")
# summary(fit_ord2)
```


## Regression on scale averages

Recall, Kara already looked at a normal regression on responses with `r1_vaccIntent` model.

### Normal regression: predicting post-test

```{r}
d2 <- d_scored %>% filter(scale=="vaccIntent") %>% spread(phase,mean) %>% mutate(condition = relevel(condition, ref="noInterv"))

contrasts(d2$condition) <- cbind(diseaseRisk = c(0, 1))

fit.lm <- lm(post ~ scale(pre) * condition,
                    data=d2)
summary(fit.lm)
```

### Beta regression: response

A beta regression on the responses accords with the linear regression on responses--slight positive effect of diseaseRisk, slight negative effect of autism correction, but too much uncertainty overall.

But, our response variable isn't really all that appropriate for a linear regression, even if many researchers would be happy with that results and move on. Instead, vaccIntent is bounded and highly skewed. That makes it suitable for beta regression.

```{r}
rescale_beta <- function(x, lower, upper) {
  # rescales onto the open interval (0,1)
  # rescales over theoretical bounds of measurement, specified by "upper" and "lower"
  # based on Smithson & Verkuilen (2006), though this is not as principled as you might think
  # see http://dx.doi.org/10.1037/1082-989X.11.1.54.supp

  N <- length(x)
  res <- (x-lower)/(upper - lower)
  res <- (res*(N-1) + .5)/N

  return(as.vector(res))
}
# 
# fit.betaR<- brm(mean ~ condition * phase + (1|workerId), 
#                data=d_scored %>% mutate(mean = rescale_beta(mean,-3,3)),
#                family=Beta(),
#                control = list(adapt_delta = .85),
#                cores = parallel::detectCores(),
#                iter = 2000)
# 
# summary(fit.betaR)
```

### Beta regresstion: posttest


```{r}
library(betareg)

contrasts(d2$condition) <- cbind(diseaseRisk = c(0, 1))

fit.betaInt <- betareg(post ~ scale(pre) * condition,
                    data=d2 %>% mutate(post=rescale_beta(post,-3,3)))

summary(fit.betaInt)
```

A plot ...

```{r}

fit.olsScaled <- lm(post ~ scale(pre) * condition, data=d2 %>% mutate(post=rescale_beta(post,-3,3)))

d2 %>% 
  mutate(post=rescale_beta(post,-3,3)) %>%
  select(condition, pre, post) %>%
  bind_cols(predict(fit.betaInt) %>% as_tibble()) %>%
  rename(predictionBeta=value) %>%
  bind_cols(predict(fit.olsScaled) %>% as_tibble()) %>%
  rename(predictionOLS=value) %>%

ggplot(aes(x = pre, y = post, color=condition)) +
  geom_jitter(height=.1, width=.05, alpha=.8, shape=1) +
  geom_line(aes(y = predictionBeta, linetype="Beta")) +
  geom_line(aes(y = predictionOLS, linetype="OLS")) +
  # geom_line(aes(y = predict(fit.ols, vaccW),
  #               colour = "OLS", linetype = "OLS")) +
  # scale_colour_manual("", values = c("red", "blue")) +
  scale_linetype_manual("", values = c("solid", "dashed")) +
  theme_bw()
```

